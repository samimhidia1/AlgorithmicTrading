{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU",
  "language_info": {
   "name": "python"
  },
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "PJG2VIq6gr9G",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "21f91330-bc05-4529-b294-c1e49f8ed8cf"
   },
   "source": [
    "!wget -nc https://lazyprogrammer.me/course_files/sp500_closefull.csv"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2023-03-08 14:40:11--  https://lazyprogrammer.me/course_files/sp500_closefull.csv\n",
      "Resolving lazyprogrammer.me (lazyprogrammer.me)... 2606:4700:3031::6815:17d2, 2606:4700:3030::ac43:d5a6, 104.21.23.210, ...\n",
      "Connecting to lazyprogrammer.me (lazyprogrammer.me)|2606:4700:3031::6815:17d2|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 18464866 (18M) [text/csv]\n",
      "Saving to: â€˜sp500_closefull.csvâ€™\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  0%  320K 56s\n",
      "    50K .......... .......... .......... .......... ..........  0%  311K 57s\n",
      "   100K .......... .......... .......... .......... ..........  0%  316K 57s\n",
      "   150K .......... .......... .......... .......... ..........  1%  318K 56s\n",
      "   200K .......... .......... .......... .......... ..........  1% 23.5M 45s\n",
      "   250K .......... .......... .......... .......... ..........  1% 1.24M 40s\n",
      "   300K .......... .......... .......... .......... ..........  1%  423K 40s\n",
      "   350K .......... .......... .......... .......... ..........  2% 3.93M 35s\n",
      "   400K .......... .......... .......... .......... ..........  2%  342K 37s\n",
      "   450K .......... .......... .......... .......... ..........  2% 39.4M 33s\n",
      "   500K .......... .......... .......... .......... ..........  3% 18.2M 30s\n",
      "   550K .......... .......... .......... .......... ..........  3% 1.20M 29s\n",
      "   600K .......... .......... .......... .......... ..........  3%  406K 30s\n",
      "   650K .......... .......... .......... .......... ..........  3% 20.2M 28s\n",
      "   700K .......... .......... .......... .......... ..........  4% 86.6M 26s\n",
      "   750K .......... .......... .......... .......... ..........  4% 20.8M 24s\n",
      "   800K .......... .......... .......... .......... ..........  4%  344K 26s\n",
      "   850K .......... .......... .......... .......... ..........  4% 36.4M 24s\n",
      "   900K .......... .......... .......... .......... ..........  5% 39.0M 23s\n",
      "   950K .......... .......... .......... .......... ..........  5% 2.65M 22s\n",
      "  1000K .......... .......... .......... .......... ..........  5% 29.3M 21s\n",
      "  1050K .......... .......... .......... .......... ..........  6%  354K 22s\n",
      "  1100K .......... .......... .......... .......... ..........  6% 4.18M 21s\n",
      "  1150K .......... .......... .......... .......... ..........  6% 9.99M 20s\n",
      "  1200K .......... .......... .......... .......... ..........  6% 72.7M 19s\n",
      "  1250K .......... .......... .......... .......... ..........  7% 3.99M 19s\n",
      "  1300K .......... .......... .......... .......... ..........  7% 62.0M 18s\n",
      "  1350K .......... .......... .......... .......... ..........  7% 65.5M 17s\n",
      "  1400K .......... .......... .......... .......... ..........  8%  397K 18s\n",
      "  1450K .......... .......... .......... .......... ..........  8% 31.6M 18s\n",
      "  1500K .......... .......... .......... .......... ..........  8% 96.1M 17s\n",
      "  1550K .......... .......... .......... .......... ..........  8% 1.14M 17s\n",
      "  1600K .......... .......... .......... .......... ..........  9% 32.4M 16s\n",
      "  1650K .......... .......... .......... .......... ..........  9%  101M 16s\n",
      "  1700K .......... .......... .......... .......... ..........  9%  117M 15s\n",
      "  1750K .......... .......... .......... .......... ..........  9% 6.20M 15s\n",
      "  1800K .......... .......... .......... .......... .......... 10% 63.5M 14s\n",
      "  1850K .......... .......... .......... .......... .......... 10%  390K 15s\n",
      "  1900K .......... .......... .......... .......... .......... 10% 82.8M 15s\n",
      "  1950K .......... .......... .......... .......... .......... 11% 48.9M 14s\n",
      "  2000K .......... .......... .......... .......... .......... 11% 4.57M 14s\n",
      "  2050K .......... .......... .......... .......... .......... 11% 50.6M 14s\n",
      "  2100K .......... .......... .......... .......... .......... 11% 43.0M 13s\n",
      "  2150K .......... .......... .......... .......... .......... 12% 44.5M 13s\n",
      "  2200K .......... .......... .......... .......... .......... 12%  410K 13s\n",
      "  2250K .......... .......... .......... .......... .......... 12% 9.21M 13s\n",
      "  2300K .......... .......... .......... .......... .......... 13% 7.52M 13s\n",
      "  2350K .......... .......... .......... .......... .......... 13% 42.1M 13s\n",
      "  2400K .......... .......... .......... .......... .......... 13% 55.1M 12s\n",
      "  2450K .......... .......... .......... .......... .......... 13%  116M 12s\n",
      "  2500K .......... .......... .......... .......... .......... 14% 30.4M 12s\n",
      "  2550K .......... .......... .......... .......... .......... 14% 39.2M 11s\n",
      "  2600K .......... .......... .......... .......... .......... 14% 35.1M 11s\n",
      "  2650K .......... .......... .......... .......... .......... 14% 27.6M 11s\n",
      "  2700K .......... .......... .......... .......... .......... 15% 33.8M 11s\n",
      "  2750K .......... .......... .......... .......... .......... 15%  340K 11s\n",
      "  2800K .......... .......... .......... .......... .......... 15% 8.28M 11s\n",
      "  2850K .......... .......... .......... .......... .......... 16% 43.0M 11s\n",
      "  2900K .......... .......... .......... .......... .......... 16% 20.0M 11s\n",
      "  2950K .......... .......... .......... .......... .......... 16% 67.0M 10s\n",
      "  3000K .......... .......... .......... .......... .......... 16% 24.3M 10s\n",
      "  3050K .......... .......... .......... .......... .......... 17% 35.8M 10s\n",
      "  3100K .......... .......... .......... .......... .......... 17%  101M 10s\n",
      "  3150K .......... .......... .......... .......... .......... 17%  334K 10s\n",
      "  3200K .......... .......... .......... .......... .......... 18% 29.6M 10s\n",
      "  3250K .......... .......... .......... .......... .......... 18% 3.05M 10s\n",
      "  3300K .......... .......... .......... .......... .......... 18% 39.7M 10s\n",
      "  3350K .......... .......... .......... .......... .......... 18%  364K 10s\n",
      "  3400K .......... .......... .......... .......... .......... 19% 18.4M 10s\n",
      "  3450K .......... .......... .......... .......... .......... 19% 28.6M 10s\n",
      "  3500K .......... .......... .......... .......... .......... 19%  106M 10s\n",
      "  3550K .......... .......... .......... .......... .......... 19% 43.2M 10s\n",
      "  3600K .......... .......... .......... .......... .......... 20%  349K 10s\n",
      "  3650K .......... .......... .......... .......... .......... 20% 9.98M 10s\n",
      "  3700K .......... .......... .......... .......... .......... 20% 41.3M 10s\n",
      "  3750K .......... .......... .......... .......... .......... 21% 22.0M 10s\n",
      "  3800K .......... .......... .......... .......... .......... 21% 28.5M 9s\n",
      "  3850K .......... .......... .......... .......... .......... 21% 42.5M 9s\n",
      "  3900K .......... .......... .......... .......... .......... 21% 42.7M 9s\n",
      "  3950K .......... .......... .......... .......... .......... 22% 27.7M 9s\n",
      "  4000K .......... .......... .......... .......... .......... 22% 1.36M 9s\n",
      "  4050K .......... .......... .......... .......... .......... 22% 89.2M 9s\n",
      "  4100K .......... .......... .......... .......... .......... 23%  421K 9s\n",
      "  4150K .......... .......... .......... .......... .......... 23% 35.2M 9s\n",
      "  4200K .......... .......... .......... .......... .......... 23%  101M 9s\n",
      "  4250K .......... .......... .......... .......... .......... 23%  113M 9s\n",
      "  4300K .......... .......... .......... .......... .......... 24% 61.0M 9s\n",
      "  4350K .......... .......... .......... .......... .......... 24%  344K 9s\n",
      "  4400K .......... .......... .......... .......... .......... 24% 44.8M 9s\n",
      "  4450K .......... .......... .......... .......... .......... 24% 59.6M 9s\n",
      "  4500K .......... .......... .......... .......... .......... 25% 13.5M 9s\n",
      "  4550K .......... .......... .......... .......... .......... 25% 27.3M 8s\n",
      "  4600K .......... .......... .......... .......... .......... 25%  338K 9s\n",
      "  4650K .......... .......... .......... .......... .......... 26% 57.7M 9s\n",
      "  4700K .......... .......... .......... .......... .......... 26% 12.7M 8s\n",
      "  4750K .......... .......... .......... .......... .......... 26% 1.93M 8s\n",
      "  4800K .......... .......... .......... .......... .......... 26% 43.0M 8s\n",
      "  4850K .......... .......... .......... .......... .......... 27%  103M 8s\n",
      "  4900K .......... .......... .......... .......... .......... 27%  390K 8s\n",
      "  4950K .......... .......... .......... .......... .......... 27% 50.5M 8s\n",
      "  5000K .......... .......... .......... .......... .......... 28% 4.88M 8s\n",
      "  5050K .......... .......... .......... .......... .......... 28% 42.2M 8s\n",
      "  5100K .......... .......... .......... .......... .......... 28% 64.8M 8s\n",
      "  5150K .......... .......... .......... .......... .......... 28% 69.1M 8s\n",
      "  5200K .......... .......... .......... .......... .......... 29% 1.32M 8s\n",
      "  5250K .......... .......... .......... .......... .......... 29%  423K 8s\n",
      "  5300K .......... .......... .......... .......... .......... 29% 25.7M 8s\n",
      "  5350K .......... .......... .......... .......... .......... 29% 42.2M 8s\n",
      "  5400K .......... .......... .......... .......... .......... 30% 9.50M 8s\n",
      "  5450K .......... .......... .......... .......... .......... 30% 36.0M 8s\n",
      "  5500K .......... .......... .......... .......... .......... 30%  328K 8s\n",
      "  5550K .......... .......... .......... .......... .......... 31% 13.0M 8s\n",
      "  5600K .......... .......... .......... .......... .......... 31% 55.0M 8s\n",
      "  5650K .......... .......... .......... .......... .......... 31% 57.7M 8s\n",
      "  5700K .......... .......... .......... .......... .......... 31% 51.4M 8s\n",
      "  5750K .......... .......... .......... .......... .......... 32% 32.6M 7s\n",
      "  5800K .......... .......... .......... .......... .......... 32% 85.2M 7s\n",
      "  5850K .......... .......... .......... .......... .......... 32%  363K 8s\n",
      "  5900K .......... .......... .......... .......... .......... 32% 4.80M 7s\n",
      "  5950K .......... .......... .......... .......... .......... 33% 8.97M 7s\n",
      "  6000K .......... .......... .......... .......... .......... 33% 20.2M 7s\n",
      "  6050K .......... .......... .......... .......... .......... 33% 30.5M 7s\n",
      "  6100K .......... .......... .......... .......... .......... 34% 22.8M 7s\n",
      "  6150K .......... .......... .......... .......... .......... 34%  161K 8s\n",
      "  6200K .......... .......... .......... .......... .......... 34% 3.24M 8s\n",
      "  6250K .......... .......... .......... .......... .......... 34% 12.4M 7s\n",
      "  6300K .......... .......... .......... .......... .......... 35% 63.3M 7s\n",
      "  6350K .......... .......... .......... .......... .......... 35% 4.33M 7s\n",
      "  6400K .......... .......... .......... .......... .......... 35% 2.55M 7s\n",
      "  6450K .......... .......... .......... .......... .......... 36% 14.1M 7s\n",
      "  6500K .......... .......... .......... .......... .......... 36% 46.0M 7s\n",
      "  6550K .......... .......... .......... .......... .......... 36% 40.4M 7s\n",
      "  6600K .......... .......... .......... .......... .......... 36% 99.6M 7s\n",
      "  6650K .......... .......... .......... .......... .......... 37%  541K 7s\n",
      "  6700K .......... .......... .......... .......... .......... 37% 43.4M 7s\n",
      "  6750K .......... .......... .......... .......... .......... 37% 25.8M 7s\n",
      "  6800K .......... .......... .......... .......... .......... 37% 18.3M 7s\n",
      "  6850K .......... .......... .......... .......... .......... 38% 1.25M 7s\n",
      "  6900K .......... .......... .......... .......... .......... 38%  182K 7s\n",
      "  6950K .......... .......... .......... .......... .......... 38% 14.0M 7s\n",
      "  7000K .......... .......... .......... .......... .......... 39% 17.9M 7s\n",
      "  7050K .......... .......... .......... .......... .......... 39% 25.5M 7s\n",
      "  7100K .......... .......... .......... .......... .......... 39% 1.26M 7s\n",
      "  7150K .......... .......... .......... .......... .......... 39% 30.7M 7s\n",
      "  7200K .......... .......... .......... .......... .......... 40% 64.5M 7s\n",
      "  7250K .......... .......... .......... .......... .......... 40% 36.8M 7s\n",
      "  7300K .......... .......... .......... .......... .......... 40%  455K 7s\n",
      "  7350K .......... .......... .......... .......... .......... 41% 10.7M 7s\n",
      "  7400K .......... .......... .......... .......... .......... 41% 58.1M 7s\n",
      "  7450K .......... .......... .......... .......... .......... 41%  326K 7s\n",
      "  7500K .......... .......... .......... .......... .......... 41% 6.01M 7s\n",
      "  7550K .......... .......... .......... .......... .......... 42% 1.40M 7s\n",
      "  7600K .......... .......... .......... .......... .......... 42%  418K 7s\n",
      "  7650K .......... .......... .......... .......... .......... 42% 23.9M 7s\n",
      "  7700K .......... .......... .......... .......... .......... 42% 92.9M 7s\n",
      "  7750K .......... .......... .......... .......... .......... 43%  321K 7s\n",
      "  7800K .......... .......... .......... .......... .......... 43%  310K 7s\n",
      "  7850K .......... .......... .......... .......... .......... 43% 9.68M 7s\n",
      "  7900K .......... .......... .......... .......... .......... 44% 28.0M 7s\n",
      "  7950K .......... .......... .......... .......... .......... 44% 27.3M 7s\n",
      "  8000K .......... .......... .......... .......... .......... 44%  292K 7s\n",
      "  8050K .......... .......... .......... .......... .......... 44% 3.37M 7s\n",
      "  8100K .......... .......... .......... .......... .......... 45% 2.43M 7s\n",
      "  8150K .......... .......... .......... .......... .......... 45% 4.07M 7s\n",
      "  8200K .......... .......... .......... .......... .......... 45%  483K 7s\n",
      "  8250K .......... .......... .......... .......... .......... 46% 1.48M 7s\n",
      "  8300K .......... .......... .......... .......... .......... 46% 2.21M 7s\n",
      "  8350K .......... .......... .......... .......... .......... 46%  538K 7s\n",
      "  8400K .......... .......... .......... .......... .......... 46% 62.5M 7s\n",
      "  8450K .......... .......... .......... .......... .......... 47% 16.1M 6s\n",
      "  8500K .......... .......... .......... .......... .......... 47%  199K 7s\n",
      "  8550K .......... .......... .......... .......... .......... 47%  331K 7s\n",
      "  8600K .......... .......... .......... .......... .......... 47% 46.9M 7s\n",
      "  8650K .......... .......... .......... .......... .......... 48%  113M 7s\n",
      "  8700K .......... .......... .......... .......... .......... 48%  685K 7s\n",
      "  8750K .......... .......... .......... .......... .......... 48%  255K 7s\n",
      "  8800K .......... .......... .......... .......... .......... 49% 46.4M 7s\n",
      "  8850K .......... .......... .......... .......... .......... 49%  182K 7s\n",
      "  8900K .......... .......... .......... .......... .......... 49%  297K 7s\n",
      "  8950K .......... .......... .......... .......... .......... 49%  327K 7s\n",
      "  9000K .......... .......... .......... .......... .......... 50% 36.8M 7s\n",
      "  9050K .......... .......... .......... .......... .......... 50% 22.2M 7s\n",
      "  9100K .......... .......... .......... .......... .......... 50%  259K 7s\n",
      "  9150K .......... .......... .......... .......... .......... 51%  247K 7s\n",
      "  9200K .......... .......... .......... .......... .......... 51%  216K 7s\n",
      "  9250K .......... .......... .......... .......... .......... 51% 16.5M 7s\n",
      "  9300K .......... .......... .......... .......... .......... 51%  320K 7s\n",
      "  9350K .......... .......... .......... .......... .......... 52%  309K 7s\n",
      "  9400K .......... .......... .......... .......... .......... 52%  312K 7s\n",
      "  9450K .......... .......... .......... .......... .......... 52% 35.1M 7s\n",
      "  9500K .......... .......... .......... .......... .......... 52%  316K 7s\n",
      "  9550K .......... .......... .......... .......... .......... 53%  294K 7s\n",
      "  9600K .......... .......... .......... .......... .......... 53%  332K 7s\n",
      "  9650K .......... .......... .......... .......... .......... 53%  319K 8s\n",
      "  9700K .......... .......... .......... .......... .......... 54% 40.7M 7s\n",
      "  9750K .......... .......... .......... .......... .......... 54%  257K 8s\n",
      "  9800K .......... .......... .......... .......... .......... 54%  296K 8s\n",
      "  9850K .......... .......... .......... .......... .......... 54%  328K 8s\n",
      "  9900K .......... .......... .......... .......... .......... 55% 72.0M 8s\n",
      "  9950K .......... .......... .......... .......... .......... 55%  193K 8s\n",
      " 10000K .......... .......... .......... .......... .......... 55%  278K 8s\n",
      " 10050K .......... .......... .......... .......... .......... 56%  161K 8s\n",
      " 10100K .......... .......... .......... .......... .......... 56% 13.4M 8s\n",
      " 10150K .......... .......... .......... .......... .......... 56% 9.95M 8s\n",
      " 10200K .......... .......... .......... .......... .......... 56%  253K 8s\n",
      " 10250K .......... .......... .......... .......... .......... 57%  186K 8s\n",
      " 10300K .......... .......... .......... .......... .......... 57%  248K 8s\n",
      " 10350K .......... .......... .......... .......... .......... 57%  314K 8s\n",
      " 10400K .......... .......... .......... .......... .......... 57% 40.1M 8s\n",
      " 10450K .......... .......... .......... .......... .......... 58%  190K 8s\n",
      " 10500K .......... .......... .......... .......... .......... 58%  285K 8s\n",
      " 10550K .......... .......... .......... .......... .......... 58%  328K 8s\n",
      " 10600K .......... .......... .......... .......... .......... 59% 15.9M 8s\n",
      " 10650K .......... .......... .......... .......... .......... 59%  300K 8s\n",
      " 10700K .......... .......... .......... .......... .......... 59%  317K 8s\n",
      " 10750K .......... .......... .......... .......... .......... 59%  259K 8s\n",
      " 10800K .......... .......... .......... .......... .......... 60%  315K 8s\n",
      " 10850K .......... .......... .......... .......... .......... 60% 18.9M 8s\n",
      " 10900K .......... .......... .......... .......... .......... 60%  281K 8s\n",
      " 10950K .......... .......... .......... .......... .......... 61%  196K 8s\n",
      " 11000K .......... .......... .......... .......... .......... 61%  247K 8s\n",
      " 11050K .......... .......... .......... .......... .......... 61% 14.6M 8s\n",
      " 11100K .......... .......... .......... .......... .......... 61%  314K 8s\n",
      " 11150K .......... .......... .......... .......... .......... 62%  170K 8s\n",
      " 11200K .......... .......... .......... .......... .......... 62%  284K 8s\n",
      " 11250K .......... .......... .......... .......... .......... 62%  303K 8s\n",
      " 11300K .......... .......... .......... .......... .......... 62% 22.4M 8s\n",
      " 11350K .......... .......... .......... .......... .......... 63%  255K 8s\n",
      " 11400K .......... .......... .......... .......... .......... 63%  224K 8s\n",
      " 11450K .......... .......... .......... .......... .......... 63%  240K 8s\n",
      " 11500K .......... .......... .......... .......... .......... 64% 36.5M 8s\n",
      " 11550K .......... .......... .......... .......... .......... 64%  315K 8s\n",
      " 11600K .......... .......... .......... .......... .......... 64%  181K 8s\n",
      " 11650K .......... .......... .......... .......... .......... 64%  249K 8s\n",
      " 11700K .......... .......... .......... .......... .......... 65%  114K 8s\n",
      " 11750K .......... .......... .......... .......... .......... 65% 65.5M 8s\n",
      " 11800K .......... .......... .......... .......... .......... 65% 1.08M 8s\n",
      " 11850K .......... .......... .......... .......... .......... 65%  160K 8s\n",
      " 11900K .......... .......... .......... .......... .......... 66%  158K 8s\n",
      " 11950K .......... .......... .......... .......... .......... 66%  182K 8s\n",
      " 12000K .......... .......... .......... .......... .......... 66% 37.1M 8s\n",
      " 12050K .......... .......... .......... .......... .......... 67%  161K 8s\n",
      " 12100K .......... .......... .......... .......... .......... 67%  233K 8s\n",
      " 12150K .......... .......... .......... .......... .......... 67%  159K 8s\n",
      " 12200K .......... .......... .......... .......... .......... 67% 65.0M 8s\n",
      " 12250K .......... .......... .......... .......... .......... 68%  182K 8s\n",
      " 12300K .......... .......... .......... .......... .......... 68%  202K 8s\n",
      " 12350K .......... .......... .......... .......... .......... 68%  184K 8s\n",
      " 12400K .......... .......... .......... .......... .......... 69%  105K 8s\n",
      " 12450K .......... .......... .......... .......... .......... 69% 32.9M 8s\n",
      " 12500K .......... .......... .......... .......... .......... 69%  306K 8s\n",
      " 12550K .......... .......... .......... .......... .......... 69%  119K 8s\n",
      " 12600K .......... .......... .......... .......... .......... 70%  158K 8s\n",
      " 12650K .......... .......... .......... .......... .......... 70% 13.7M 8s\n",
      " 12700K .......... .......... .......... .......... .......... 70%  236K 8s\n",
      " 12750K .......... .......... .......... .......... .......... 70%  157K 8s\n",
      " 12800K .......... .......... .......... .......... .......... 71%  185K 8s\n",
      " 12850K .......... .......... .......... .......... .......... 71%  161K 8s\n",
      " 12900K .......... .......... .......... .......... .......... 71% 21.7M 8s\n",
      " 12950K .......... .......... .......... .......... .......... 72%  196K 8s\n",
      " 13000K .......... .......... .......... .......... .......... 72%  157K 8s\n",
      " 13050K .......... .......... .......... .......... .......... 72%  217K 8s\n",
      " 13100K .......... .......... .......... .......... .......... 72% 42.8M 8s\n",
      " 13150K .......... .......... .......... .......... .......... 73%  124K 8s\n",
      " 13200K .......... .......... .......... .......... .......... 73%  155K 8s\n",
      " 13250K .......... .......... .......... .......... .......... 73%  131K 8s\n",
      " 13300K .......... .......... .......... .......... .......... 74%  157K 8s\n",
      " 13350K .......... .......... .......... .......... .......... 74% 27.3M 8s\n",
      " 13400K .......... .......... .......... .......... .......... 74%  123K 8s\n",
      " 13450K .......... .......... .......... .......... .......... 74%  130K 8s\n",
      " 13500K .......... .......... .......... .......... .......... 75%  127K 8s\n",
      " 13550K .......... .......... .......... .......... .......... 75%  157K 8s\n",
      " 13600K .......... .......... .......... .......... .......... 75% 40.2M 8s\n",
      " 13650K .......... .......... .......... .......... .......... 75%  149K 8s\n",
      " 13700K .......... .......... .......... .......... .......... 76% 92.3K 8s\n",
      " 13750K .......... .......... .......... .......... .......... 76%  199K 8s\n",
      " 13800K .......... .......... .......... .......... .......... 76% 39.4M 8s\n",
      " 13850K .......... .......... .......... .......... .......... 77%  130K 8s\n",
      " 13900K .......... .......... .......... .......... .......... 77%  157K 8s\n",
      " 13950K .......... .......... .......... .......... .......... 77% 88.1K 8s\n",
      " 14000K .......... .......... .......... .......... .......... 77%  222K 8s\n",
      " 14050K .......... .......... .......... .......... .......... 78% 35.8M 7s\n",
      " 14100K .......... .......... .......... .......... .......... 78%  105K 7s\n",
      " 14150K .......... .......... .......... .......... .......... 78%  157K 7s\n",
      " 14200K .......... .......... .......... .......... .......... 79%  103K 7s\n",
      " 14250K .......... .......... .......... .......... .......... 79% 18.6M 7s\n",
      " 14300K .......... .......... .......... .......... .......... 79%  157K 7s\n",
      " 14350K .......... .......... .......... .......... .......... 79%  105K 7s\n",
      " 14400K .......... .......... .......... .......... .......... 80%  157K 7s\n",
      " 14450K .......... .......... .......... .......... .......... 80%  158K 7s\n",
      " 14500K .......... .......... .......... .......... .......... 80% 40.8M 7s\n",
      " 14550K .......... .......... .......... .......... .......... 80%  141K 7s\n",
      " 14600K .......... .......... .......... .......... .......... 81% 83.4K 7s\n",
      " 14650K .......... .......... .......... .......... .......... 81%  122K 7s\n",
      " 14700K .......... .......... .......... .......... .......... 81% 38.9M 7s\n",
      " 14750K .......... .......... .......... .......... .......... 82%  118K 7s\n",
      " 14800K .......... .......... .......... .......... .......... 82%  112K 7s\n",
      " 14850K .......... .......... .......... .......... .......... 82%  104K 7s\n",
      " 14900K .......... .......... .......... .......... .......... 82%  106K 7s\n",
      " 14950K .......... .......... .......... .......... .......... 83% 35.5M 7s\n",
      " 15000K .......... .......... .......... .......... .......... 83%  106K 7s\n",
      " 15050K .......... .......... .......... .......... .......... 83%  124K 7s\n",
      " 15100K .......... .......... .......... .......... .......... 84%  116K 6s\n",
      " 15150K .......... .......... .......... .......... .......... 84%  115K 6s\n",
      " 15200K .......... .......... .......... .......... .......... 84% 6.82M 6s\n",
      " 15250K .......... .......... .......... .......... .......... 84%  122K 6s\n",
      " 15300K .......... .......... .......... .......... .......... 85%  120K 6s\n",
      " 15350K .......... .......... .......... .......... .......... 85%  131K 6s\n",
      " 15400K .......... .......... .......... .......... .......... 85% 43.6M 6s\n",
      " 15450K .......... .......... .......... .......... .......... 85%  131K 6s\n",
      " 15500K .......... .......... .......... .......... .......... 86%  143K 6s\n",
      " 15550K .......... .......... .......... .......... .......... 86%  156K 6s\n",
      " 15600K .......... .......... .......... .......... .......... 86%  115K 6s\n",
      " 15650K .......... .......... .......... .......... .......... 87% 23.6M 6s\n",
      " 15700K .......... .......... .......... .......... .......... 87%  151K 5s\n",
      " 15750K .......... .......... .......... .......... .......... 87%  145K 5s\n",
      " 15800K .......... .......... .......... .......... .......... 87%  115K 5s\n",
      " 15850K .......... .......... .......... .......... .......... 88% 42.9M 5s\n",
      " 15900K .......... .......... .......... .......... .......... 88%  114K 5s\n",
      " 15950K .......... .......... .......... .......... .......... 88%  125K 5s\n",
      " 16000K .......... .......... .......... .......... .......... 89%  134K 5s\n",
      " 16050K .......... .......... .......... .......... .......... 89%  144K 5s\n",
      " 16100K .......... .......... .......... .......... .......... 89% 71.0M 5s\n",
      " 16150K .......... .......... .......... .......... .......... 89%  136K 5s\n",
      " 16200K .......... .......... .......... .......... .......... 90%  125K 4s\n",
      " 16250K .......... .......... .......... .......... .......... 90%  149K 4s\n",
      " 16300K .......... .......... .......... .......... .......... 90% 40.7M 4s\n",
      " 16350K .......... .......... .......... .......... .......... 90%  130K 4s\n",
      " 16400K .......... .......... .......... .......... .......... 91%  148K 4s\n",
      " 16450K .......... .......... .......... .......... .......... 91%  135K 4s\n",
      " 16500K .......... .......... .......... .......... .......... 91%  131K 4s\n",
      " 16550K .......... .......... .......... .......... .......... 92%  104M 4s\n",
      " 16600K .......... .......... .......... .......... .......... 92%  148K 4s\n",
      " 16650K .......... .......... .......... .......... .......... 92%  198K 3s\n",
      " 16700K .......... .......... .......... .......... .......... 92%  202K 3s\n",
      " 16750K .......... .......... .......... .......... .......... 93%  166K 3s\n",
      " 16800K .......... .......... .......... .......... .......... 93% 39.6M 3s\n",
      " 16850K .......... .......... .......... .......... .......... 93%  206K 3s\n",
      " 16900K .......... .......... .......... .......... .......... 93%  243K 3s\n",
      " 16950K .......... .......... .......... .......... .......... 94%  242K 3s\n",
      " 17000K .......... .......... .......... .......... .......... 94% 38.3M 3s\n",
      " 17050K .......... .......... .......... .......... .......... 94%  315K 2s\n",
      " 17100K .......... .......... .......... .......... .......... 95%  224K 2s\n",
      " 17150K .......... .......... .......... .......... .......... 95%  315K 2s\n",
      " 17200K .......... .......... .......... .......... .......... 95%  316K 2s\n",
      " 17250K .......... .......... .......... .......... .......... 95% 38.7M 2s\n",
      " 17300K .......... .......... .......... .......... .......... 96%  502K 2s\n",
      " 17350K .......... .......... .......... .......... .......... 96%  302K 2s\n",
      " 17400K .......... .......... .......... .......... .......... 96%  326K 2s\n",
      " 17450K .......... .......... .......... .......... .......... 97% 3.02M 1s\n",
      " 17500K .......... .......... .......... .......... .......... 97%  542K 1s\n",
      " 17550K .......... .......... .......... .......... .......... 97%  459K 1s\n",
      " 17600K .......... .......... .......... .......... .......... 97%  520K 1s\n",
      " 17650K .......... .......... .......... .......... .......... 98%  361K 1s\n",
      " 17700K .......... .......... .......... .......... .......... 98% 74.3M 1s\n",
      " 17750K .......... .......... .......... .......... .......... 98%  606K 1s\n",
      " 17800K .......... .......... .......... .......... .......... 98%  317K 0s\n",
      " 17850K .......... .......... .......... .......... .......... 99% 10.2M 0s\n",
      " 17900K .......... .......... .......... .......... .......... 99%  136M 0s\n",
      " 17950K .......... .......... .......... .......... .......... 99% 33.9M 0s\n",
      " 18000K .......... .......... .......... ..                   100% 55.6M=46s\n",
      "\n",
      "2023-03-08 14:40:58 (393 KB/s) - â€˜sp500_closefull.csvâ€™ saved [18464866/18464866]\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lKG-ydbihXDo"
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X9V983hpqlvM"
   },
   "source": [
    "# Read CSV"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "S3DqRzvvhZ85"
   },
   "source": [
    "df0 = pd.read_csv('sp500_closefull.csv', index_col=0, parse_dates=True)\n",
    "#df0 = pd.read_csv('BTCUSDT-2000000-tp-20-sl-20facto 1.csv')\n",
    "df0.dropna(axis=0, how='all', inplace=True)\n",
    "df0.dropna(axis=1, how='any', inplace=True)"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 640
    },
    "id": "lYcb08yFWSEG",
    "outputId": "53ccd944-072f-4dc7-83fd-e7de353ce575"
   },
   "source": [
    "df0"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                 CSCO        UAL       TROW        ISRG       PRGO        TPR  \\\nDate                                                                            \n2010-01-04  24.690001  12.800000  54.400002  102.923332  40.349998  36.310001   \n2010-01-05  24.580000  13.910000  55.009998  102.459999  38.790001  36.750000   \n2010-01-06  24.420000  13.270000  54.150002  103.946663  38.299999  37.470001   \n2010-01-07  24.530001  13.550000  54.110001  103.556664  37.990002  37.490002   \n2010-01-08  24.660000  13.330000  53.900002  102.986664  37.779999  37.270000   \n...               ...        ...        ...         ...        ...        ...   \n2018-12-21  41.849998  81.470001  86.779999  446.019989  37.029999  32.810001   \n2018-12-24  40.279999  79.120003  84.949997  434.890015  36.500000  32.299999   \n2018-12-26  42.470001  83.800003  89.650002  461.980011  40.700001  33.889999   \n2018-12-27  42.910000  83.040001  91.309998  468.700012  39.619999  34.150002   \n2018-12-28  42.770000  83.169998  91.339996  471.200012  39.919998  33.810001   \n\n                  DVN        MRO          BA        VRTX  ...          M  \\\nDate                                                      ...              \n2010-01-04  76.570000  19.153616   56.180000   44.240002  ...  17.059999   \n2010-01-05  76.650002  19.171511   58.020000   42.779999  ...  16.860001   \n2010-01-06  76.419998  19.595024   59.779999   42.029999  ...  17.100000   \n2010-01-07  75.970001  19.475725   62.200001   41.500000  ...  17.490000   \n2010-01-08  76.120003  19.505550   61.599998   40.669998  ...  16.920000   \n...               ...        ...         ...         ...  ...        ...   \n2018-12-21  21.910000  13.450000  304.549988  156.500000  ...  28.200001   \n2018-12-24  20.980000  12.660000  294.160004  151.910004  ...  28.150000   \n2018-12-26  22.709999  14.170000  313.929993  161.839996  ...  30.129999   \n2018-12-27  22.900000  14.290000  317.140015  162.369995  ...  30.040001   \n2018-12-28  22.459999  14.080000  316.380005  161.419998  ...  30.020000   \n\n                   CRM        PGR         WAT        BWA        LRCX  \\\nDate                                                                   \n2010-01-04   18.705000  18.030001   61.630001  16.889999   39.880001   \n2010-01-05   18.625000  17.969999   60.790001  17.695000   39.610001   \n2010-01-06   18.592501  17.790001   60.900002  18.344999   39.430000   \n2010-01-07   18.510000  17.549999   61.160000  18.594999   39.360001   \n2010-01-08   18.537500  17.709999   61.209999  18.254999   40.349998   \n...                ...        ...         ...        ...         ...   \n2018-12-21  122.910004  59.419998  176.559998  33.770000  127.160004   \n2018-12-24  121.330002  57.070000  173.539993  33.200001  123.279999   \n2018-12-26  130.839996  59.330002  181.190002  34.400002  130.839996   \n2018-12-27  135.199997  60.200001  185.179993  34.770000  133.279999   \n2018-12-28  134.679993  59.650002  184.759995  34.509998  135.419998   \n\n                  NWL        UAA         BLK        PPL  \nDate                                                     \n2010-01-04  15.200000   3.510000  238.580002  30.242558  \n2010-01-05  15.110000   3.615000  239.610001  29.851370  \n2010-01-06  15.380000   3.695000  234.669998  29.916569  \n2010-01-07  15.820000   3.651250  237.250000  29.627834  \n2010-01-08  15.770000   3.643750  238.919998  29.534695  \n...               ...        ...         ...        ...  \n2018-12-21  18.860001  16.959999  369.160004  28.400000  \n2018-12-24  17.950001  16.750000  361.769989  27.590000  \n2018-12-26  18.910000  17.820000  381.230011  28.309999  \n2018-12-27  18.400000  17.910000  387.799988  28.340000  \n2018-12-28  18.379999  17.520000  388.230011  28.350000  \n\n[2263 rows x 429 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CSCO</th>\n      <th>UAL</th>\n      <th>TROW</th>\n      <th>ISRG</th>\n      <th>PRGO</th>\n      <th>TPR</th>\n      <th>DVN</th>\n      <th>MRO</th>\n      <th>BA</th>\n      <th>VRTX</th>\n      <th>...</th>\n      <th>M</th>\n      <th>CRM</th>\n      <th>PGR</th>\n      <th>WAT</th>\n      <th>BWA</th>\n      <th>LRCX</th>\n      <th>NWL</th>\n      <th>UAA</th>\n      <th>BLK</th>\n      <th>PPL</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2010-01-04</th>\n      <td>24.690001</td>\n      <td>12.800000</td>\n      <td>54.400002</td>\n      <td>102.923332</td>\n      <td>40.349998</td>\n      <td>36.310001</td>\n      <td>76.570000</td>\n      <td>19.153616</td>\n      <td>56.180000</td>\n      <td>44.240002</td>\n      <td>...</td>\n      <td>17.059999</td>\n      <td>18.705000</td>\n      <td>18.030001</td>\n      <td>61.630001</td>\n      <td>16.889999</td>\n      <td>39.880001</td>\n      <td>15.200000</td>\n      <td>3.510000</td>\n      <td>238.580002</td>\n      <td>30.242558</td>\n    </tr>\n    <tr>\n      <th>2010-01-05</th>\n      <td>24.580000</td>\n      <td>13.910000</td>\n      <td>55.009998</td>\n      <td>102.459999</td>\n      <td>38.790001</td>\n      <td>36.750000</td>\n      <td>76.650002</td>\n      <td>19.171511</td>\n      <td>58.020000</td>\n      <td>42.779999</td>\n      <td>...</td>\n      <td>16.860001</td>\n      <td>18.625000</td>\n      <td>17.969999</td>\n      <td>60.790001</td>\n      <td>17.695000</td>\n      <td>39.610001</td>\n      <td>15.110000</td>\n      <td>3.615000</td>\n      <td>239.610001</td>\n      <td>29.851370</td>\n    </tr>\n    <tr>\n      <th>2010-01-06</th>\n      <td>24.420000</td>\n      <td>13.270000</td>\n      <td>54.150002</td>\n      <td>103.946663</td>\n      <td>38.299999</td>\n      <td>37.470001</td>\n      <td>76.419998</td>\n      <td>19.595024</td>\n      <td>59.779999</td>\n      <td>42.029999</td>\n      <td>...</td>\n      <td>17.100000</td>\n      <td>18.592501</td>\n      <td>17.790001</td>\n      <td>60.900002</td>\n      <td>18.344999</td>\n      <td>39.430000</td>\n      <td>15.380000</td>\n      <td>3.695000</td>\n      <td>234.669998</td>\n      <td>29.916569</td>\n    </tr>\n    <tr>\n      <th>2010-01-07</th>\n      <td>24.530001</td>\n      <td>13.550000</td>\n      <td>54.110001</td>\n      <td>103.556664</td>\n      <td>37.990002</td>\n      <td>37.490002</td>\n      <td>75.970001</td>\n      <td>19.475725</td>\n      <td>62.200001</td>\n      <td>41.500000</td>\n      <td>...</td>\n      <td>17.490000</td>\n      <td>18.510000</td>\n      <td>17.549999</td>\n      <td>61.160000</td>\n      <td>18.594999</td>\n      <td>39.360001</td>\n      <td>15.820000</td>\n      <td>3.651250</td>\n      <td>237.250000</td>\n      <td>29.627834</td>\n    </tr>\n    <tr>\n      <th>2010-01-08</th>\n      <td>24.660000</td>\n      <td>13.330000</td>\n      <td>53.900002</td>\n      <td>102.986664</td>\n      <td>37.779999</td>\n      <td>37.270000</td>\n      <td>76.120003</td>\n      <td>19.505550</td>\n      <td>61.599998</td>\n      <td>40.669998</td>\n      <td>...</td>\n      <td>16.920000</td>\n      <td>18.537500</td>\n      <td>17.709999</td>\n      <td>61.209999</td>\n      <td>18.254999</td>\n      <td>40.349998</td>\n      <td>15.770000</td>\n      <td>3.643750</td>\n      <td>238.919998</td>\n      <td>29.534695</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2018-12-21</th>\n      <td>41.849998</td>\n      <td>81.470001</td>\n      <td>86.779999</td>\n      <td>446.019989</td>\n      <td>37.029999</td>\n      <td>32.810001</td>\n      <td>21.910000</td>\n      <td>13.450000</td>\n      <td>304.549988</td>\n      <td>156.500000</td>\n      <td>...</td>\n      <td>28.200001</td>\n      <td>122.910004</td>\n      <td>59.419998</td>\n      <td>176.559998</td>\n      <td>33.770000</td>\n      <td>127.160004</td>\n      <td>18.860001</td>\n      <td>16.959999</td>\n      <td>369.160004</td>\n      <td>28.400000</td>\n    </tr>\n    <tr>\n      <th>2018-12-24</th>\n      <td>40.279999</td>\n      <td>79.120003</td>\n      <td>84.949997</td>\n      <td>434.890015</td>\n      <td>36.500000</td>\n      <td>32.299999</td>\n      <td>20.980000</td>\n      <td>12.660000</td>\n      <td>294.160004</td>\n      <td>151.910004</td>\n      <td>...</td>\n      <td>28.150000</td>\n      <td>121.330002</td>\n      <td>57.070000</td>\n      <td>173.539993</td>\n      <td>33.200001</td>\n      <td>123.279999</td>\n      <td>17.950001</td>\n      <td>16.750000</td>\n      <td>361.769989</td>\n      <td>27.590000</td>\n    </tr>\n    <tr>\n      <th>2018-12-26</th>\n      <td>42.470001</td>\n      <td>83.800003</td>\n      <td>89.650002</td>\n      <td>461.980011</td>\n      <td>40.700001</td>\n      <td>33.889999</td>\n      <td>22.709999</td>\n      <td>14.170000</td>\n      <td>313.929993</td>\n      <td>161.839996</td>\n      <td>...</td>\n      <td>30.129999</td>\n      <td>130.839996</td>\n      <td>59.330002</td>\n      <td>181.190002</td>\n      <td>34.400002</td>\n      <td>130.839996</td>\n      <td>18.910000</td>\n      <td>17.820000</td>\n      <td>381.230011</td>\n      <td>28.309999</td>\n    </tr>\n    <tr>\n      <th>2018-12-27</th>\n      <td>42.910000</td>\n      <td>83.040001</td>\n      <td>91.309998</td>\n      <td>468.700012</td>\n      <td>39.619999</td>\n      <td>34.150002</td>\n      <td>22.900000</td>\n      <td>14.290000</td>\n      <td>317.140015</td>\n      <td>162.369995</td>\n      <td>...</td>\n      <td>30.040001</td>\n      <td>135.199997</td>\n      <td>60.200001</td>\n      <td>185.179993</td>\n      <td>34.770000</td>\n      <td>133.279999</td>\n      <td>18.400000</td>\n      <td>17.910000</td>\n      <td>387.799988</td>\n      <td>28.340000</td>\n    </tr>\n    <tr>\n      <th>2018-12-28</th>\n      <td>42.770000</td>\n      <td>83.169998</td>\n      <td>91.339996</td>\n      <td>471.200012</td>\n      <td>39.919998</td>\n      <td>33.810001</td>\n      <td>22.459999</td>\n      <td>14.080000</td>\n      <td>316.380005</td>\n      <td>161.419998</td>\n      <td>...</td>\n      <td>30.020000</td>\n      <td>134.679993</td>\n      <td>59.650002</td>\n      <td>184.759995</td>\n      <td>34.509998</td>\n      <td>135.419998</td>\n      <td>18.379999</td>\n      <td>17.520000</td>\n      <td>388.230011</td>\n      <td>28.350000</td>\n    </tr>\n  </tbody>\n</table>\n<p>2263 rows × 429 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bZaWmoNKq6yP"
   },
   "source": [
    "# Prepare DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RhArIA5uhbUt"
   },
   "source": [
    "df_returns = pd.DataFrame()\n",
    "for name in df0.columns:\n",
    "  df_returns[name] = np.log(df0[name]).diff()"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "C:\\Users\\samim\\AppData\\Local\\Temp\\ipykernel_13364\\1269682969.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 640
    },
    "id": "dN8EU9jzWEID",
    "outputId": "916b6d97-89e5-495f-99c6-3a8a16077c96"
   },
   "source": [
    "df_returns"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "                CSCO       UAL      TROW      ISRG      PRGO       TPR  \\\nDate                                                                     \n2010-01-04       NaN       NaN       NaN       NaN       NaN       NaN   \n2010-01-05 -0.004465  0.083163  0.011151 -0.004512 -0.039429  0.012045   \n2010-01-06 -0.006531 -0.047102 -0.015757  0.014405 -0.012713  0.019402   \n2010-01-07  0.004494  0.020881 -0.000739 -0.003759 -0.008127  0.000534   \n2010-01-08  0.005286 -0.016369 -0.003889 -0.005519 -0.005543 -0.005886   \n...              ...       ...       ...       ...       ...       ...   \n2018-12-21 -0.015177 -0.035451 -0.005974 -0.030602 -0.346415 -0.018122   \n2018-12-24 -0.038237 -0.029269 -0.021313 -0.025271 -0.014416 -0.015666   \n2018-12-26  0.052943  0.057467  0.053850  0.060428  0.108916  0.048053   \n2018-12-27  0.010307 -0.009111  0.018347  0.014441 -0.026894  0.007643   \n2018-12-28 -0.003268  0.001564  0.000328  0.005320  0.007543 -0.010006   \n\n                 DVN       MRO        BA      VRTX  ...         M       CRM  \\\nDate                                                ...                       \n2010-01-04       NaN       NaN       NaN       NaN  ...       NaN       NaN   \n2010-01-05  0.001044  0.000934  0.032227 -0.033559  ... -0.011793 -0.004286   \n2010-01-06 -0.003005  0.021850  0.029883 -0.017687  ...  0.014134 -0.001746   \n2010-01-07 -0.005906 -0.006107  0.039684 -0.012690  ...  0.022551 -0.004447   \n2010-01-08  0.001973  0.001530 -0.009693 -0.020203  ... -0.033133  0.001485   \n...              ...       ...       ...       ...  ...       ...       ...   \n2018-12-21 -0.027017 -0.011826 -0.027528 -0.030210  ... -0.032103 -0.038466   \n2018-12-24 -0.043374 -0.060532 -0.034711 -0.029768  ... -0.001775 -0.012938   \n2018-12-26  0.079236  0.112680  0.065046  0.063320  ...  0.067974  0.075461   \n2018-12-27  0.008332  0.008433  0.010173  0.003269  ... -0.002991  0.032780   \n2018-12-28 -0.019401 -0.014805 -0.002399 -0.005868  ... -0.000666 -0.003854   \n\n                 PGR       WAT       BWA      LRCX       NWL       UAA  \\\nDate                                                                     \n2010-01-04       NaN       NaN       NaN       NaN       NaN       NaN   \n2010-01-05 -0.003333 -0.013723  0.046560 -0.006793 -0.005939  0.029476   \n2010-01-06 -0.010067  0.001808  0.036075 -0.004555  0.017711  0.021889   \n2010-01-07 -0.013583  0.004260  0.013536 -0.001777  0.028207 -0.011911   \n2010-01-08  0.009075  0.000817 -0.018454  0.024841 -0.003166 -0.002056   \n...              ...       ...       ...       ...       ...       ...   \n2018-12-21 -0.006375 -0.007055 -0.005610 -0.009003 -0.060188 -0.042142   \n2018-12-24 -0.040352 -0.017253 -0.017023 -0.030988 -0.049453 -0.012459   \n2018-12-26  0.038837  0.043138  0.035507  0.059517  0.052101  0.061923   \n2018-12-27  0.014557  0.021782  0.010698  0.018477 -0.027340  0.005038   \n2018-12-28 -0.009178 -0.002271 -0.007506  0.015929 -0.001088 -0.022016   \n\n                 BLK       PPL  \nDate                            \n2010-01-04       NaN       NaN  \n2010-01-05  0.004308 -0.013019  \n2010-01-06 -0.020832  0.002182  \n2010-01-07  0.010934 -0.009698  \n2010-01-08  0.007014 -0.003149  \n...              ...       ...  \n2018-12-21 -0.006776 -0.010508  \n2018-12-24 -0.020222 -0.028936  \n2018-12-26  0.052394  0.025762  \n2018-12-27  0.017087  0.001059  \n2018-12-28  0.001108  0.000353  \n\n[2263 rows x 429 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CSCO</th>\n      <th>UAL</th>\n      <th>TROW</th>\n      <th>ISRG</th>\n      <th>PRGO</th>\n      <th>TPR</th>\n      <th>DVN</th>\n      <th>MRO</th>\n      <th>BA</th>\n      <th>VRTX</th>\n      <th>...</th>\n      <th>M</th>\n      <th>CRM</th>\n      <th>PGR</th>\n      <th>WAT</th>\n      <th>BWA</th>\n      <th>LRCX</th>\n      <th>NWL</th>\n      <th>UAA</th>\n      <th>BLK</th>\n      <th>PPL</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2010-01-04</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2010-01-05</th>\n      <td>-0.004465</td>\n      <td>0.083163</td>\n      <td>0.011151</td>\n      <td>-0.004512</td>\n      <td>-0.039429</td>\n      <td>0.012045</td>\n      <td>0.001044</td>\n      <td>0.000934</td>\n      <td>0.032227</td>\n      <td>-0.033559</td>\n      <td>...</td>\n      <td>-0.011793</td>\n      <td>-0.004286</td>\n      <td>-0.003333</td>\n      <td>-0.013723</td>\n      <td>0.046560</td>\n      <td>-0.006793</td>\n      <td>-0.005939</td>\n      <td>0.029476</td>\n      <td>0.004308</td>\n      <td>-0.013019</td>\n    </tr>\n    <tr>\n      <th>2010-01-06</th>\n      <td>-0.006531</td>\n      <td>-0.047102</td>\n      <td>-0.015757</td>\n      <td>0.014405</td>\n      <td>-0.012713</td>\n      <td>0.019402</td>\n      <td>-0.003005</td>\n      <td>0.021850</td>\n      <td>0.029883</td>\n      <td>-0.017687</td>\n      <td>...</td>\n      <td>0.014134</td>\n      <td>-0.001746</td>\n      <td>-0.010067</td>\n      <td>0.001808</td>\n      <td>0.036075</td>\n      <td>-0.004555</td>\n      <td>0.017711</td>\n      <td>0.021889</td>\n      <td>-0.020832</td>\n      <td>0.002182</td>\n    </tr>\n    <tr>\n      <th>2010-01-07</th>\n      <td>0.004494</td>\n      <td>0.020881</td>\n      <td>-0.000739</td>\n      <td>-0.003759</td>\n      <td>-0.008127</td>\n      <td>0.000534</td>\n      <td>-0.005906</td>\n      <td>-0.006107</td>\n      <td>0.039684</td>\n      <td>-0.012690</td>\n      <td>...</td>\n      <td>0.022551</td>\n      <td>-0.004447</td>\n      <td>-0.013583</td>\n      <td>0.004260</td>\n      <td>0.013536</td>\n      <td>-0.001777</td>\n      <td>0.028207</td>\n      <td>-0.011911</td>\n      <td>0.010934</td>\n      <td>-0.009698</td>\n    </tr>\n    <tr>\n      <th>2010-01-08</th>\n      <td>0.005286</td>\n      <td>-0.016369</td>\n      <td>-0.003889</td>\n      <td>-0.005519</td>\n      <td>-0.005543</td>\n      <td>-0.005886</td>\n      <td>0.001973</td>\n      <td>0.001530</td>\n      <td>-0.009693</td>\n      <td>-0.020203</td>\n      <td>...</td>\n      <td>-0.033133</td>\n      <td>0.001485</td>\n      <td>0.009075</td>\n      <td>0.000817</td>\n      <td>-0.018454</td>\n      <td>0.024841</td>\n      <td>-0.003166</td>\n      <td>-0.002056</td>\n      <td>0.007014</td>\n      <td>-0.003149</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2018-12-21</th>\n      <td>-0.015177</td>\n      <td>-0.035451</td>\n      <td>-0.005974</td>\n      <td>-0.030602</td>\n      <td>-0.346415</td>\n      <td>-0.018122</td>\n      <td>-0.027017</td>\n      <td>-0.011826</td>\n      <td>-0.027528</td>\n      <td>-0.030210</td>\n      <td>...</td>\n      <td>-0.032103</td>\n      <td>-0.038466</td>\n      <td>-0.006375</td>\n      <td>-0.007055</td>\n      <td>-0.005610</td>\n      <td>-0.009003</td>\n      <td>-0.060188</td>\n      <td>-0.042142</td>\n      <td>-0.006776</td>\n      <td>-0.010508</td>\n    </tr>\n    <tr>\n      <th>2018-12-24</th>\n      <td>-0.038237</td>\n      <td>-0.029269</td>\n      <td>-0.021313</td>\n      <td>-0.025271</td>\n      <td>-0.014416</td>\n      <td>-0.015666</td>\n      <td>-0.043374</td>\n      <td>-0.060532</td>\n      <td>-0.034711</td>\n      <td>-0.029768</td>\n      <td>...</td>\n      <td>-0.001775</td>\n      <td>-0.012938</td>\n      <td>-0.040352</td>\n      <td>-0.017253</td>\n      <td>-0.017023</td>\n      <td>-0.030988</td>\n      <td>-0.049453</td>\n      <td>-0.012459</td>\n      <td>-0.020222</td>\n      <td>-0.028936</td>\n    </tr>\n    <tr>\n      <th>2018-12-26</th>\n      <td>0.052943</td>\n      <td>0.057467</td>\n      <td>0.053850</td>\n      <td>0.060428</td>\n      <td>0.108916</td>\n      <td>0.048053</td>\n      <td>0.079236</td>\n      <td>0.112680</td>\n      <td>0.065046</td>\n      <td>0.063320</td>\n      <td>...</td>\n      <td>0.067974</td>\n      <td>0.075461</td>\n      <td>0.038837</td>\n      <td>0.043138</td>\n      <td>0.035507</td>\n      <td>0.059517</td>\n      <td>0.052101</td>\n      <td>0.061923</td>\n      <td>0.052394</td>\n      <td>0.025762</td>\n    </tr>\n    <tr>\n      <th>2018-12-27</th>\n      <td>0.010307</td>\n      <td>-0.009111</td>\n      <td>0.018347</td>\n      <td>0.014441</td>\n      <td>-0.026894</td>\n      <td>0.007643</td>\n      <td>0.008332</td>\n      <td>0.008433</td>\n      <td>0.010173</td>\n      <td>0.003269</td>\n      <td>...</td>\n      <td>-0.002991</td>\n      <td>0.032780</td>\n      <td>0.014557</td>\n      <td>0.021782</td>\n      <td>0.010698</td>\n      <td>0.018477</td>\n      <td>-0.027340</td>\n      <td>0.005038</td>\n      <td>0.017087</td>\n      <td>0.001059</td>\n    </tr>\n    <tr>\n      <th>2018-12-28</th>\n      <td>-0.003268</td>\n      <td>0.001564</td>\n      <td>0.000328</td>\n      <td>0.005320</td>\n      <td>0.007543</td>\n      <td>-0.010006</td>\n      <td>-0.019401</td>\n      <td>-0.014805</td>\n      <td>-0.002399</td>\n      <td>-0.005868</td>\n      <td>...</td>\n      <td>-0.000666</td>\n      <td>-0.003854</td>\n      <td>-0.009178</td>\n      <td>-0.002271</td>\n      <td>-0.007506</td>\n      <td>0.015929</td>\n      <td>-0.001088</td>\n      <td>-0.022016</td>\n      <td>0.001108</td>\n      <td>0.000353</td>\n    </tr>\n  </tbody>\n</table>\n<p>2263 rows × 429 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ddhGpa7nrAxK"
   },
   "source": [
    "# Split Test and Train"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wmG-1LyVhdIE"
   },
   "source": [
    "# split into train and test\n",
    "Ntest = 1000\n",
    "train_data = df_returns.iloc[:-Ntest]\n",
    "test_data = df_returns.iloc[-Ntest:]"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JIKr0tR4rnUH"
   },
   "source": [
    "# Column choice"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "pIdDBxYxhenN"
   },
   "source": [
    "feats = ['AAPL', 'MSFT', 'AMZN']"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3MVZ-J0qH4k"
   },
   "source": [
    "# Class"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MFKmicUfhgNH"
   },
   "source": [
    "class Env:\n",
    "  def __init__(self, df):\n",
    "    self.df = df\n",
    "    self.n = len(df)\n",
    "    self.current_idx = 0\n",
    "    self.action_space = [0, 1, 2] # BUY, SELL, HOLD\n",
    "    self.invested = 0\n",
    "\n",
    "    self.states = self.df[feats].to_numpy()\n",
    "    self.rewards = self.df['SPY'].to_numpy()\n",
    "\n",
    "  def reset(self):\n",
    "    self.current_idx = 0\n",
    "    return self.states[self.current_idx]\n",
    "\n",
    "  def step(self, action):\n",
    "    # need to return (next_state, reward, done)\n",
    "\n",
    "    self.current_idx += 1\n",
    "    if self.current_idx >= self.n:\n",
    "      raise Exception(\"Episode already done\")\n",
    "\n",
    "    if action == 0: # BUY\n",
    "      self.invested = 1\n",
    "    elif action == 1: # SELL\n",
    "      self.invested = 0\n",
    "    \n",
    "    # compute reward\n",
    "    if self.invested:\n",
    "      reward = self.rewards[self.current_idx]\n",
    "    else:\n",
    "      reward = 0\n",
    "\n",
    "    # state transition\n",
    "    next_state = self.states[self.current_idx]\n",
    "\n",
    "    done = (self.current_idx == self.n - 1)\n",
    "    return next_state, reward, done"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Hf2jBx2Hh16C"
   },
   "source": [
    "class StateMapper:\n",
    "  def __init__(self, env, n_bins=6, n_samples=10000):\n",
    "    # first, collect sample states from the environment\n",
    "    states = []\n",
    "    done = False\n",
    "    s = env.reset()\n",
    "    self.D = len(s) # number of elements we need to bin\n",
    "    states.append(s)\n",
    "    for _ in range(n_samples):\n",
    "      a = np.random.choice(env.action_space)\n",
    "      s2, _, done = env.step(a)\n",
    "      states.append(s2)\n",
    "      if done:\n",
    "        s = env.reset()\n",
    "        states.append(s)\n",
    "\n",
    "    # convert to numpy array for easy indexing\n",
    "    states = np.array(states)\n",
    "\n",
    "    # create the bins for each dimension\n",
    "    self.bins = []\n",
    "    for d in range(self.D):\n",
    "      column = np.sort(states[:,d])\n",
    "\n",
    "      # find the boundaries for each bin\n",
    "      current_bin = []\n",
    "      for k in range(n_bins):\n",
    "        boundary = column[int(n_samples / n_bins * (k + 0.5))]\n",
    "        current_bin.append(boundary)\n",
    "\n",
    "      self.bins.append(current_bin)\n",
    "\n",
    "\n",
    "  def transform(self, state):\n",
    "    x = np.zeros(self.D)\n",
    "    for d in range(self.D):\n",
    "      x[d] = int(np.digitize(state[d], self.bins[d]))\n",
    "    return tuple(x)\n",
    "\n",
    "\n",
    "  def all_possible_states(self):\n",
    "    list_of_bins = []\n",
    "    for d in range(self.D):\n",
    "      list_of_bins.append(list(range(len(self.bins[d]) + 1)))\n",
    "    # print(list_of_bins)\n",
    "    return itertools.product(*list_of_bins)"
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Km8vhEZ0jc0X"
   },
   "source": [
    "class Agent:\n",
    "  def __init__(self, action_size, state_mapper):\n",
    "    self.action_size = action_size\n",
    "    self.gamma = 0.8  # discount rate\n",
    "    self.epsilon = 0.1\n",
    "    self.learning_rate = 1e-1\n",
    "    self.state_mapper = state_mapper\n",
    "\n",
    "    # initialize Q-table randomly\n",
    "    self.Q = {}\n",
    "    for s in self.state_mapper.all_possible_states():\n",
    "      s = tuple(s)\n",
    "      for a in range(self.action_size):\n",
    "        self.Q[(s,a)] = np.random.randn()\n",
    "\n",
    "  def act(self, state):\n",
    "    if np.random.rand() <= self.epsilon:\n",
    "      return np.random.choice(self.action_size)\n",
    "\n",
    "    s = self.state_mapper.transform(state)\n",
    "    act_values = [self.Q[(s,a)] for a in range(self.action_size)]\n",
    "    return np.argmax(act_values)  # returns action\n",
    "\n",
    "  def train(self, state, action, reward, next_state, done):\n",
    "    s = self.state_mapper.transform(state)\n",
    "    s2 = self.state_mapper.transform(next_state)\n",
    "\n",
    "    if done:\n",
    "      target = reward\n",
    "    else:\n",
    "      act_values = [self.Q[(s2,a)] for a in range(self.action_size)]\n",
    "      target = reward + self.gamma * np.amax(act_values)\n",
    "\n",
    "    # Run one training step\n",
    "    self.Q[(s,action)] += self.learning_rate * (target - self.Q[(s,action)])"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6A3P7cxNqQ9m"
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JdFpCRUAj2b3"
   },
   "source": [
    "def play_one_episode(agent, env, is_train):\n",
    "  state = env.reset()\n",
    "  done = False\n",
    "  total_reward = 0\n",
    "  while not done:\n",
    "    action = agent.act(state)\n",
    "    next_state, reward, done = env.step(action)\n",
    "    total_reward += reward\n",
    "    if is_train:\n",
    "      agent.train(state, action, reward, next_state, done)\n",
    "    state = next_state\n",
    "\n",
    "  return total_reward"
   ],
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-80emPrwo4Xm",
    "outputId": "a8896d6a-3b8c-4ebf-9710-988ba1bf5ac5"
   },
   "source": [
    "agent"
   ],
   "execution_count": 13,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'agent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43magent\u001B[49m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'agent' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xVJk90yirO11"
   },
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nAW3BOZMj6kk"
   },
   "source": [
    "num_episodes = 500"
   ],
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OsWKAgG4j8iC"
   },
   "source": [
    "train_env = Env(train_data)\n",
    "test_env = Env(test_data)"
   ],
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "{'df':                 CSCO       UAL      TROW      ISRG      PRGO       TPR  \\\n Date                                                                     \n 2010-01-04       NaN       NaN       NaN       NaN       NaN       NaN   \n 2010-01-05 -0.004465  0.083163  0.011151 -0.004512 -0.039429  0.012045   \n 2010-01-06 -0.006531 -0.047102 -0.015757  0.014405 -0.012713  0.019402   \n 2010-01-07  0.004494  0.020881 -0.000739 -0.003759 -0.008127  0.000534   \n 2010-01-08  0.005286 -0.016369 -0.003889 -0.005519 -0.005543 -0.005886   \n ...              ...       ...       ...       ...       ...       ...   \n 2015-01-02 -0.007577 -0.008256 -0.001165 -0.006392 -0.003176 -0.006678   \n 2015-01-05 -0.020121 -0.002868 -0.023239 -0.021541 -0.010376 -0.015668   \n 2015-01-06 -0.000370 -0.024020 -0.017821  0.010482 -0.001882 -0.011776   \n 2015-01-07  0.009200  0.014603  0.014594  0.005468  0.016569  0.030388   \n 2015-01-08  0.007663  0.016797  0.011784  0.019629  0.022570  0.025071   \n \n                  DVN       MRO        BA      VRTX  ...         M       CRM  \\\n Date                                                ...                       \n 2010-01-04       NaN       NaN       NaN       NaN  ...       NaN       NaN   \n 2010-01-05  0.001044  0.000934  0.032227 -0.033559  ... -0.011793 -0.004286   \n 2010-01-06 -0.003005  0.021850  0.029883 -0.017687  ...  0.014134 -0.001746   \n 2010-01-07 -0.005906 -0.006107  0.039684 -0.012690  ...  0.022551 -0.004447   \n 2010-01-08  0.001973  0.001530 -0.009693 -0.020203  ... -0.033133  0.001485   \n ...              ...       ...       ...       ...  ...       ...       ...   \n 2015-01-02 -0.004093  0.010898 -0.000231  0.035312  ... -0.000913 -0.001181   \n 2015-01-05 -0.037778 -0.047620 -0.006950 -0.016715  ... -0.008562 -0.018227   \n 2015-01-06 -0.020655 -0.015149 -0.011848 -0.030792  ... -0.003692 -0.016816   \n 2015-01-07  0.004685  0.012211  0.015406  0.027731  ...  0.040175 -0.004731   \n 2015-01-08  0.034870  0.020026  0.017528  0.027063  ...  0.003842  0.028742   \n \n                  PGR       WAT       BWA      LRCX       NWL       UAA  \\\n Date                                                                     \n 2010-01-04       NaN       NaN       NaN       NaN       NaN       NaN   \n 2010-01-05 -0.003333 -0.013723  0.046560 -0.006793 -0.005939  0.029476   \n 2010-01-06 -0.010067  0.001808  0.036075 -0.004555  0.017711  0.021889   \n 2010-01-07 -0.013583  0.004260  0.013536 -0.001777  0.028207 -0.011911   \n 2010-01-08  0.009075  0.000817 -0.018454  0.024841 -0.003166 -0.002056   \n ...              ...       ...       ...       ...       ...       ...   \n 2015-01-02  0.001851  0.010238 -0.003829  0.001385 -0.006057 -0.014987   \n 2015-01-05 -0.011157 -0.007580 -0.029289 -0.012284 -0.011690 -0.024057   \n 2015-01-06 -0.012418 -0.004345 -0.006984 -0.016833 -0.017523 -0.016677   \n 2015-01-07  0.020612  0.029767  0.023218  0.005170  0.005965  0.035789   \n 2015-01-08  0.019832  0.018460  0.016884  0.025582  0.022983  0.025367   \n \n                  BLK       PPL  \n Date                            \n 2010-01-04       NaN       NaN  \n 2010-01-05  0.004308 -0.013019  \n 2010-01-06 -0.020832  0.002182  \n 2010-01-07  0.010934 -0.009698  \n 2010-01-08  0.007014 -0.003149  \n ...              ...       ...  \n 2015-01-02 -0.002324  0.000825  \n 2015-01-05 -0.026215 -0.023373  \n 2015-01-06 -0.015662 -0.000282  \n 2015-01-07  0.020943  0.004496  \n 2015-01-08  0.011612 -0.003933  \n \n [1263 rows x 429 columns],\n 'n': 1263,\n 'current_idx': 0,\n 'action_space': [0, 1, 2],\n 'invested': 0,\n 'states': array([[            nan,             nan,             nan],\n        [ 1.72737560e-03,  3.22995369e-04,  5.88265262e-03],\n        [-1.60341887e-02, -6.15581494e-03, -1.82817890e-02],\n        ...,\n        [ 9.41333221e-05, -1.47860985e-02, -2.30980135e-02],\n        [ 1.39247879e-02,  1.26252876e-02,  1.05439820e-02],\n        [ 3.77025114e-02,  2.89937302e-02,  6.81266999e-03]]),\n 'rewards': array([        nan,  0.0026436 ,  0.00070381, ..., -0.00946361,\n         0.01238416,  0.01758942])}"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_env.__dict__"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DJoegr4VV5U-",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 640
    },
    "outputId": "fcdf6254-e7fb-4205-b600-0e2f13b06441"
   },
   "source": [
    "train_data"
   ],
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "                CSCO       UAL      TROW      ISRG      PRGO       TPR  \\\nDate                                                                     \n2010-01-04       NaN       NaN       NaN       NaN       NaN       NaN   \n2010-01-05 -0.004465  0.083163  0.011151 -0.004512 -0.039429  0.012045   \n2010-01-06 -0.006531 -0.047102 -0.015757  0.014405 -0.012713  0.019402   \n2010-01-07  0.004494  0.020881 -0.000739 -0.003759 -0.008127  0.000534   \n2010-01-08  0.005286 -0.016369 -0.003889 -0.005519 -0.005543 -0.005886   \n...              ...       ...       ...       ...       ...       ...   \n2015-01-02 -0.007577 -0.008256 -0.001165 -0.006392 -0.003176 -0.006678   \n2015-01-05 -0.020121 -0.002868 -0.023239 -0.021541 -0.010376 -0.015668   \n2015-01-06 -0.000370 -0.024020 -0.017821  0.010482 -0.001882 -0.011776   \n2015-01-07  0.009200  0.014603  0.014594  0.005468  0.016569  0.030388   \n2015-01-08  0.007663  0.016797  0.011784  0.019629  0.022570  0.025071   \n\n                 DVN       MRO        BA      VRTX  ...         M       CRM  \\\nDate                                                ...                       \n2010-01-04       NaN       NaN       NaN       NaN  ...       NaN       NaN   \n2010-01-05  0.001044  0.000934  0.032227 -0.033559  ... -0.011793 -0.004286   \n2010-01-06 -0.003005  0.021850  0.029883 -0.017687  ...  0.014134 -0.001746   \n2010-01-07 -0.005906 -0.006107  0.039684 -0.012690  ...  0.022551 -0.004447   \n2010-01-08  0.001973  0.001530 -0.009693 -0.020203  ... -0.033133  0.001485   \n...              ...       ...       ...       ...  ...       ...       ...   \n2015-01-02 -0.004093  0.010898 -0.000231  0.035312  ... -0.000913 -0.001181   \n2015-01-05 -0.037778 -0.047620 -0.006950 -0.016715  ... -0.008562 -0.018227   \n2015-01-06 -0.020655 -0.015149 -0.011848 -0.030792  ... -0.003692 -0.016816   \n2015-01-07  0.004685  0.012211  0.015406  0.027731  ...  0.040175 -0.004731   \n2015-01-08  0.034870  0.020026  0.017528  0.027063  ...  0.003842  0.028742   \n\n                 PGR       WAT       BWA      LRCX       NWL       UAA  \\\nDate                                                                     \n2010-01-04       NaN       NaN       NaN       NaN       NaN       NaN   \n2010-01-05 -0.003333 -0.013723  0.046560 -0.006793 -0.005939  0.029476   \n2010-01-06 -0.010067  0.001808  0.036075 -0.004555  0.017711  0.021889   \n2010-01-07 -0.013583  0.004260  0.013536 -0.001777  0.028207 -0.011911   \n2010-01-08  0.009075  0.000817 -0.018454  0.024841 -0.003166 -0.002056   \n...              ...       ...       ...       ...       ...       ...   \n2015-01-02  0.001851  0.010238 -0.003829  0.001385 -0.006057 -0.014987   \n2015-01-05 -0.011157 -0.007580 -0.029289 -0.012284 -0.011690 -0.024057   \n2015-01-06 -0.012418 -0.004345 -0.006984 -0.016833 -0.017523 -0.016677   \n2015-01-07  0.020612  0.029767  0.023218  0.005170  0.005965  0.035789   \n2015-01-08  0.019832  0.018460  0.016884  0.025582  0.022983  0.025367   \n\n                 BLK       PPL  \nDate                            \n2010-01-04       NaN       NaN  \n2010-01-05  0.004308 -0.013019  \n2010-01-06 -0.020832  0.002182  \n2010-01-07  0.010934 -0.009698  \n2010-01-08  0.007014 -0.003149  \n...              ...       ...  \n2015-01-02 -0.002324  0.000825  \n2015-01-05 -0.026215 -0.023373  \n2015-01-06 -0.015662 -0.000282  \n2015-01-07  0.020943  0.004496  \n2015-01-08  0.011612 -0.003933  \n\n[1263 rows x 429 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CSCO</th>\n      <th>UAL</th>\n      <th>TROW</th>\n      <th>ISRG</th>\n      <th>PRGO</th>\n      <th>TPR</th>\n      <th>DVN</th>\n      <th>MRO</th>\n      <th>BA</th>\n      <th>VRTX</th>\n      <th>...</th>\n      <th>M</th>\n      <th>CRM</th>\n      <th>PGR</th>\n      <th>WAT</th>\n      <th>BWA</th>\n      <th>LRCX</th>\n      <th>NWL</th>\n      <th>UAA</th>\n      <th>BLK</th>\n      <th>PPL</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2010-01-04</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2010-01-05</th>\n      <td>-0.004465</td>\n      <td>0.083163</td>\n      <td>0.011151</td>\n      <td>-0.004512</td>\n      <td>-0.039429</td>\n      <td>0.012045</td>\n      <td>0.001044</td>\n      <td>0.000934</td>\n      <td>0.032227</td>\n      <td>-0.033559</td>\n      <td>...</td>\n      <td>-0.011793</td>\n      <td>-0.004286</td>\n      <td>-0.003333</td>\n      <td>-0.013723</td>\n      <td>0.046560</td>\n      <td>-0.006793</td>\n      <td>-0.005939</td>\n      <td>0.029476</td>\n      <td>0.004308</td>\n      <td>-0.013019</td>\n    </tr>\n    <tr>\n      <th>2010-01-06</th>\n      <td>-0.006531</td>\n      <td>-0.047102</td>\n      <td>-0.015757</td>\n      <td>0.014405</td>\n      <td>-0.012713</td>\n      <td>0.019402</td>\n      <td>-0.003005</td>\n      <td>0.021850</td>\n      <td>0.029883</td>\n      <td>-0.017687</td>\n      <td>...</td>\n      <td>0.014134</td>\n      <td>-0.001746</td>\n      <td>-0.010067</td>\n      <td>0.001808</td>\n      <td>0.036075</td>\n      <td>-0.004555</td>\n      <td>0.017711</td>\n      <td>0.021889</td>\n      <td>-0.020832</td>\n      <td>0.002182</td>\n    </tr>\n    <tr>\n      <th>2010-01-07</th>\n      <td>0.004494</td>\n      <td>0.020881</td>\n      <td>-0.000739</td>\n      <td>-0.003759</td>\n      <td>-0.008127</td>\n      <td>0.000534</td>\n      <td>-0.005906</td>\n      <td>-0.006107</td>\n      <td>0.039684</td>\n      <td>-0.012690</td>\n      <td>...</td>\n      <td>0.022551</td>\n      <td>-0.004447</td>\n      <td>-0.013583</td>\n      <td>0.004260</td>\n      <td>0.013536</td>\n      <td>-0.001777</td>\n      <td>0.028207</td>\n      <td>-0.011911</td>\n      <td>0.010934</td>\n      <td>-0.009698</td>\n    </tr>\n    <tr>\n      <th>2010-01-08</th>\n      <td>0.005286</td>\n      <td>-0.016369</td>\n      <td>-0.003889</td>\n      <td>-0.005519</td>\n      <td>-0.005543</td>\n      <td>-0.005886</td>\n      <td>0.001973</td>\n      <td>0.001530</td>\n      <td>-0.009693</td>\n      <td>-0.020203</td>\n      <td>...</td>\n      <td>-0.033133</td>\n      <td>0.001485</td>\n      <td>0.009075</td>\n      <td>0.000817</td>\n      <td>-0.018454</td>\n      <td>0.024841</td>\n      <td>-0.003166</td>\n      <td>-0.002056</td>\n      <td>0.007014</td>\n      <td>-0.003149</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2015-01-02</th>\n      <td>-0.007577</td>\n      <td>-0.008256</td>\n      <td>-0.001165</td>\n      <td>-0.006392</td>\n      <td>-0.003176</td>\n      <td>-0.006678</td>\n      <td>-0.004093</td>\n      <td>0.010898</td>\n      <td>-0.000231</td>\n      <td>0.035312</td>\n      <td>...</td>\n      <td>-0.000913</td>\n      <td>-0.001181</td>\n      <td>0.001851</td>\n      <td>0.010238</td>\n      <td>-0.003829</td>\n      <td>0.001385</td>\n      <td>-0.006057</td>\n      <td>-0.014987</td>\n      <td>-0.002324</td>\n      <td>0.000825</td>\n    </tr>\n    <tr>\n      <th>2015-01-05</th>\n      <td>-0.020121</td>\n      <td>-0.002868</td>\n      <td>-0.023239</td>\n      <td>-0.021541</td>\n      <td>-0.010376</td>\n      <td>-0.015668</td>\n      <td>-0.037778</td>\n      <td>-0.047620</td>\n      <td>-0.006950</td>\n      <td>-0.016715</td>\n      <td>...</td>\n      <td>-0.008562</td>\n      <td>-0.018227</td>\n      <td>-0.011157</td>\n      <td>-0.007580</td>\n      <td>-0.029289</td>\n      <td>-0.012284</td>\n      <td>-0.011690</td>\n      <td>-0.024057</td>\n      <td>-0.026215</td>\n      <td>-0.023373</td>\n    </tr>\n    <tr>\n      <th>2015-01-06</th>\n      <td>-0.000370</td>\n      <td>-0.024020</td>\n      <td>-0.017821</td>\n      <td>0.010482</td>\n      <td>-0.001882</td>\n      <td>-0.011776</td>\n      <td>-0.020655</td>\n      <td>-0.015149</td>\n      <td>-0.011848</td>\n      <td>-0.030792</td>\n      <td>...</td>\n      <td>-0.003692</td>\n      <td>-0.016816</td>\n      <td>-0.012418</td>\n      <td>-0.004345</td>\n      <td>-0.006984</td>\n      <td>-0.016833</td>\n      <td>-0.017523</td>\n      <td>-0.016677</td>\n      <td>-0.015662</td>\n      <td>-0.000282</td>\n    </tr>\n    <tr>\n      <th>2015-01-07</th>\n      <td>0.009200</td>\n      <td>0.014603</td>\n      <td>0.014594</td>\n      <td>0.005468</td>\n      <td>0.016569</td>\n      <td>0.030388</td>\n      <td>0.004685</td>\n      <td>0.012211</td>\n      <td>0.015406</td>\n      <td>0.027731</td>\n      <td>...</td>\n      <td>0.040175</td>\n      <td>-0.004731</td>\n      <td>0.020612</td>\n      <td>0.029767</td>\n      <td>0.023218</td>\n      <td>0.005170</td>\n      <td>0.005965</td>\n      <td>0.035789</td>\n      <td>0.020943</td>\n      <td>0.004496</td>\n    </tr>\n    <tr>\n      <th>2015-01-08</th>\n      <td>0.007663</td>\n      <td>0.016797</td>\n      <td>0.011784</td>\n      <td>0.019629</td>\n      <td>0.022570</td>\n      <td>0.025071</td>\n      <td>0.034870</td>\n      <td>0.020026</td>\n      <td>0.017528</td>\n      <td>0.027063</td>\n      <td>...</td>\n      <td>0.003842</td>\n      <td>0.028742</td>\n      <td>0.019832</td>\n      <td>0.018460</td>\n      <td>0.016884</td>\n      <td>0.025582</td>\n      <td>0.022983</td>\n      <td>0.025367</td>\n      <td>0.011612</td>\n      <td>-0.003933</td>\n    </tr>\n  </tbody>\n</table>\n<p>1263 rows × 429 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "G3y2acdekASs"
   },
   "source": [
    "action_size = len(train_env.action_space)\n",
    "state_mapper = StateMapper(train_env)\n",
    "agent = Agent(action_size, state_mapper)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gfLKH_7jrkGw"
   },
   "source": [
    "train_rewards = np.empty(num_episodes)\n",
    "test_rewards = np.empty(num_episodes)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tbyGUnGRqbqL"
   },
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QAIMvbElro1v",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e65d922a-e87e-4c28-dad4-834e7883f4eb"
   },
   "source": [
    "for e in range(num_episodes):\n",
    "  r = play_one_episode(agent, train_env, is_train=True)\n",
    "  train_rewards[e] = r\n",
    "\n",
    "  # test on the test set\n",
    "  tmp_epsilon = agent.epsilon\n",
    "  agent.epsilon = 0.\n",
    "  tr = play_one_episode(agent, test_env, is_train=False)\n",
    "  agent.epsilon = tmp_epsilon\n",
    "  test_rewards[e] = tr\n",
    "\n",
    "  print(f\"eps: {e + 1}/{num_episodes}, train: {r:.5f}, test: {tr:.5f}\")"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "eps: 1/500, train: 0.17432, test: -0.02462\n",
      "eps: 2/500, train: 0.37401, test: -0.04968\n",
      "eps: 3/500, train: 0.19343, test: 0.16268\n",
      "eps: 4/500, train: 0.30016, test: -0.05417\n",
      "eps: 5/500, train: 0.43478, test: -0.04200\n",
      "eps: 6/500, train: 0.39544, test: 0.06487\n",
      "eps: 7/500, train: 0.45522, test: 0.02595\n",
      "eps: 8/500, train: 0.31319, test: 0.00396\n",
      "eps: 9/500, train: 0.07127, test: 0.05717\n",
      "eps: 10/500, train: 0.48963, test: 0.13232\n",
      "eps: 11/500, train: 0.38161, test: -0.09868\n",
      "eps: 12/500, train: 0.04224, test: 0.13195\n",
      "eps: 13/500, train: 0.35320, test: 0.03676\n",
      "eps: 14/500, train: 0.27769, test: -0.03054\n",
      "eps: 15/500, train: 0.40158, test: -0.14522\n",
      "eps: 16/500, train: 0.38251, test: -0.10042\n",
      "eps: 17/500, train: 0.31626, test: -0.06074\n",
      "eps: 18/500, train: 0.24349, test: 0.08160\n",
      "eps: 19/500, train: 0.13293, test: -0.05147\n",
      "eps: 20/500, train: 0.21604, test: 0.09362\n",
      "eps: 21/500, train: 0.36446, test: -0.09481\n",
      "eps: 22/500, train: 0.27907, test: 0.02748\n",
      "eps: 23/500, train: 0.36629, test: 0.03604\n",
      "eps: 24/500, train: 0.27047, test: 0.13253\n",
      "eps: 25/500, train: 0.40394, test: 0.04345\n",
      "eps: 26/500, train: 0.30296, test: 0.12743\n",
      "eps: 27/500, train: 0.27972, test: 0.03185\n",
      "eps: 28/500, train: 0.40362, test: 0.08551\n",
      "eps: 29/500, train: 0.08798, test: 0.11804\n",
      "eps: 30/500, train: 0.08468, test: 0.16860\n",
      "eps: 31/500, train: 0.20146, test: 0.01141\n",
      "eps: 32/500, train: 0.45387, test: 0.10812\n",
      "eps: 33/500, train: 0.35656, test: 0.08585\n",
      "eps: 34/500, train: 0.62447, test: 0.09273\n",
      "eps: 35/500, train: 0.08125, test: 0.14584\n",
      "eps: 36/500, train: 0.45505, test: 0.03011\n",
      "eps: 37/500, train: 0.12182, test: -0.00051\n",
      "eps: 38/500, train: 0.61688, test: 0.01361\n",
      "eps: 39/500, train: -0.05485, test: -0.02472\n",
      "eps: 40/500, train: 0.17392, test: 0.16459\n",
      "eps: 41/500, train: 0.07347, test: 0.08921\n",
      "eps: 42/500, train: 0.44051, test: 0.09797\n",
      "eps: 43/500, train: 0.25862, test: 0.19367\n",
      "eps: 44/500, train: 0.32370, test: 0.19275\n",
      "eps: 45/500, train: 0.07111, test: -0.03533\n",
      "eps: 46/500, train: 0.17895, test: -0.05146\n",
      "eps: 47/500, train: 0.39698, test: 0.06947\n",
      "eps: 48/500, train: 0.56354, test: 0.17063\n",
      "eps: 49/500, train: 0.51275, test: 0.32016\n",
      "eps: 50/500, train: 0.14076, test: -0.03282\n",
      "eps: 51/500, train: 0.20321, test: 0.46723\n",
      "eps: 52/500, train: 0.15121, test: 0.05110\n",
      "eps: 53/500, train: 0.18665, test: 0.06835\n",
      "eps: 54/500, train: 0.06599, test: 0.33202\n",
      "eps: 55/500, train: 0.34169, test: 0.19281\n",
      "eps: 56/500, train: 0.24655, test: 0.23184\n",
      "eps: 57/500, train: 0.43945, test: 0.24770\n",
      "eps: 58/500, train: 0.29726, test: 0.07285\n",
      "eps: 59/500, train: 0.43156, test: -0.01342\n",
      "eps: 60/500, train: 0.51765, test: -0.03437\n",
      "eps: 61/500, train: 0.34637, test: 0.42021\n",
      "eps: 62/500, train: 0.19292, test: 0.00501\n",
      "eps: 63/500, train: 0.55451, test: 0.02851\n",
      "eps: 64/500, train: 0.26659, test: 0.17957\n",
      "eps: 65/500, train: 0.31315, test: 0.21543\n",
      "eps: 66/500, train: 0.37645, test: 0.02358\n",
      "eps: 67/500, train: 0.21464, test: 0.18356\n",
      "eps: 68/500, train: 0.43520, test: 0.21760\n",
      "eps: 69/500, train: 0.26696, test: 0.25316\n",
      "eps: 70/500, train: 0.28700, test: 0.15914\n",
      "eps: 71/500, train: 0.07880, test: 0.16704\n",
      "eps: 72/500, train: 0.27914, test: 0.12271\n",
      "eps: 73/500, train: 0.43463, test: 0.09205\n",
      "eps: 74/500, train: 0.48556, test: 0.20222\n",
      "eps: 75/500, train: 0.36545, test: 0.21266\n",
      "eps: 76/500, train: 0.58175, test: 0.23556\n",
      "eps: 77/500, train: 0.79086, test: 0.18828\n",
      "eps: 78/500, train: 0.58049, test: 0.28408\n",
      "eps: 79/500, train: 0.57154, test: 0.21726\n",
      "eps: 80/500, train: 0.34388, test: 0.19370\n",
      "eps: 81/500, train: 0.36322, test: 0.30178\n",
      "eps: 82/500, train: 0.65216, test: 0.14434\n",
      "eps: 83/500, train: 0.68598, test: 0.24329\n",
      "eps: 84/500, train: 0.17244, test: -0.09001\n",
      "eps: 85/500, train: 0.57235, test: 0.03071\n",
      "eps: 86/500, train: 0.77070, test: -0.01800\n",
      "eps: 87/500, train: 0.35119, test: 0.02500\n",
      "eps: 88/500, train: 0.49023, test: -0.01313\n",
      "eps: 89/500, train: 0.33733, test: 0.03135\n",
      "eps: 90/500, train: 0.33162, test: 0.08914\n",
      "eps: 91/500, train: 0.71638, test: 0.12549\n",
      "eps: 92/500, train: 0.64942, test: 0.08716\n",
      "eps: 93/500, train: 0.53537, test: 0.15721\n",
      "eps: 94/500, train: 0.59028, test: 0.16277\n",
      "eps: 95/500, train: 0.83392, test: 0.29317\n",
      "eps: 96/500, train: 0.52360, test: 0.20959\n",
      "eps: 97/500, train: 0.63745, test: 0.26911\n",
      "eps: 98/500, train: 0.59146, test: 0.26013\n",
      "eps: 99/500, train: 0.62339, test: 0.25657\n",
      "eps: 100/500, train: 0.56289, test: 0.08252\n",
      "eps: 101/500, train: 0.79117, test: 0.28141\n",
      "eps: 102/500, train: 0.73551, test: 0.39372\n",
      "eps: 103/500, train: 0.82568, test: 0.18941\n",
      "eps: 104/500, train: 0.92891, test: -0.04534\n",
      "eps: 105/500, train: 0.87888, test: 0.29448\n",
      "eps: 106/500, train: 0.71236, test: 0.13906\n",
      "eps: 107/500, train: 0.75246, test: 0.14488\n",
      "eps: 108/500, train: 0.91313, test: 0.13439\n",
      "eps: 109/500, train: 0.93828, test: 0.23390\n",
      "eps: 110/500, train: 0.89656, test: 0.13380\n",
      "eps: 111/500, train: 0.81979, test: 0.19268\n",
      "eps: 112/500, train: 0.98885, test: 0.22165\n",
      "eps: 113/500, train: 1.04891, test: 0.41040\n",
      "eps: 114/500, train: 0.84793, test: 0.23860\n",
      "eps: 115/500, train: 0.89602, test: 0.28722\n",
      "eps: 116/500, train: 0.98206, test: 0.30995\n",
      "eps: 117/500, train: 0.92766, test: 0.24980\n",
      "eps: 118/500, train: 1.01733, test: 0.20797\n",
      "eps: 119/500, train: 0.76938, test: 0.26438\n",
      "eps: 120/500, train: 0.81483, test: 0.30466\n",
      "eps: 121/500, train: 0.75717, test: 0.42714\n",
      "eps: 122/500, train: 1.02553, test: 0.26587\n",
      "eps: 123/500, train: 0.82512, test: 0.29667\n",
      "eps: 124/500, train: 1.00784, test: 0.48094\n",
      "eps: 125/500, train: 0.84354, test: 0.49849\n",
      "eps: 126/500, train: 0.96122, test: 0.48040\n",
      "eps: 127/500, train: 0.82886, test: 0.37431\n",
      "eps: 128/500, train: 0.96502, test: 0.36761\n",
      "eps: 129/500, train: 0.96570, test: 0.40027\n",
      "eps: 130/500, train: 0.85152, test: 0.27429\n",
      "eps: 131/500, train: 0.86165, test: 0.42159\n",
      "eps: 132/500, train: 0.97745, test: 0.41602\n",
      "eps: 133/500, train: 0.90575, test: 0.21142\n",
      "eps: 134/500, train: 1.01203, test: 0.38412\n",
      "eps: 135/500, train: 0.89962, test: 0.33902\n",
      "eps: 136/500, train: 0.68514, test: 0.30436\n",
      "eps: 137/500, train: 0.93248, test: 0.32830\n",
      "eps: 138/500, train: 1.04909, test: 0.41082\n",
      "eps: 139/500, train: 1.02125, test: 0.43158\n",
      "eps: 140/500, train: 1.04194, test: 0.27367\n",
      "eps: 141/500, train: 1.00013, test: 0.33843\n",
      "eps: 142/500, train: 1.02225, test: 0.38032\n",
      "eps: 143/500, train: 1.09558, test: 0.34183\n",
      "eps: 144/500, train: 1.14401, test: 0.31485\n",
      "eps: 145/500, train: 1.05016, test: 0.50429\n",
      "eps: 146/500, train: 1.00454, test: 0.38254\n",
      "eps: 147/500, train: 0.96763, test: 0.34715\n",
      "eps: 148/500, train: 1.11748, test: 0.43658\n",
      "eps: 149/500, train: 0.86311, test: 0.48269\n",
      "eps: 150/500, train: 1.17880, test: 0.40799\n",
      "eps: 151/500, train: 1.09286, test: 0.41264\n",
      "eps: 152/500, train: 1.14707, test: 0.44591\n",
      "eps: 153/500, train: 1.12698, test: 0.38720\n",
      "eps: 154/500, train: 1.14904, test: 0.51285\n",
      "eps: 155/500, train: 0.88282, test: 0.46135\n",
      "eps: 156/500, train: 0.93778, test: 0.27843\n",
      "eps: 157/500, train: 0.99624, test: 0.27913\n",
      "eps: 158/500, train: 1.06928, test: 0.18589\n",
      "eps: 159/500, train: 1.10700, test: 0.26909\n",
      "eps: 160/500, train: 1.01636, test: 0.33204\n",
      "eps: 161/500, train: 0.81592, test: 0.42848\n",
      "eps: 162/500, train: 1.02754, test: 0.36841\n",
      "eps: 163/500, train: 0.97633, test: 0.38502\n",
      "eps: 164/500, train: 1.11715, test: 0.38312\n",
      "eps: 165/500, train: 1.12997, test: 0.27742\n",
      "eps: 166/500, train: 1.09882, test: 0.39890\n",
      "eps: 167/500, train: 1.27700, test: 0.38227\n",
      "eps: 168/500, train: 1.25411, test: 0.33240\n",
      "eps: 169/500, train: 1.23542, test: 0.41059\n",
      "eps: 170/500, train: 1.19776, test: 0.37581\n",
      "eps: 171/500, train: 1.18305, test: 0.43195\n",
      "eps: 172/500, train: 1.04871, test: 0.33215\n",
      "eps: 173/500, train: 1.00538, test: 0.41433\n",
      "eps: 174/500, train: 1.11669, test: 0.40159\n",
      "eps: 175/500, train: 1.08845, test: 0.36341\n",
      "eps: 176/500, train: 1.02934, test: 0.39806\n",
      "eps: 177/500, train: 1.09503, test: 0.34042\n",
      "eps: 178/500, train: 1.18169, test: 0.33603\n",
      "eps: 179/500, train: 1.12132, test: 0.24699\n",
      "eps: 180/500, train: 1.10109, test: 0.24161\n",
      "eps: 181/500, train: 1.11671, test: 0.33290\n",
      "eps: 182/500, train: 1.03679, test: 0.34637\n",
      "eps: 183/500, train: 1.21251, test: 0.28539\n",
      "eps: 184/500, train: 1.26412, test: 0.25044\n",
      "eps: 185/500, train: 1.11826, test: 0.31029\n",
      "eps: 186/500, train: 1.22703, test: 0.33587\n",
      "eps: 187/500, train: 1.27160, test: 0.38564\n",
      "eps: 188/500, train: 1.15749, test: 0.34892\n",
      "eps: 189/500, train: 1.18514, test: 0.31124\n",
      "eps: 190/500, train: 1.25753, test: 0.35104\n",
      "eps: 191/500, train: 1.16440, test: 0.34220\n",
      "eps: 192/500, train: 1.36390, test: 0.30876\n",
      "eps: 193/500, train: 1.24213, test: 0.38059\n",
      "eps: 194/500, train: 1.28201, test: 0.45180\n",
      "eps: 195/500, train: 1.45654, test: 0.53886\n",
      "eps: 196/500, train: 1.29741, test: 0.46904\n",
      "eps: 197/500, train: 1.28377, test: 0.47602\n",
      "eps: 198/500, train: 1.42284, test: 0.42308\n",
      "eps: 199/500, train: 1.42467, test: 0.37541\n",
      "eps: 200/500, train: 1.31057, test: 0.44012\n",
      "eps: 201/500, train: 1.30368, test: 0.45418\n",
      "eps: 202/500, train: 1.26993, test: 0.43545\n",
      "eps: 203/500, train: 1.33284, test: 0.36425\n",
      "eps: 204/500, train: 1.45498, test: 0.26469\n",
      "eps: 205/500, train: 1.32793, test: 0.27456\n",
      "eps: 206/500, train: 1.30434, test: 0.20922\n",
      "eps: 207/500, train: 1.27517, test: 0.28366\n",
      "eps: 208/500, train: 1.18354, test: 0.33988\n",
      "eps: 209/500, train: 1.46301, test: 0.34839\n",
      "eps: 210/500, train: 1.30934, test: 0.32187\n",
      "eps: 211/500, train: 1.48247, test: 0.22589\n",
      "eps: 212/500, train: 1.38848, test: 0.31591\n",
      "eps: 213/500, train: 1.28872, test: 0.35350\n",
      "eps: 214/500, train: 1.14700, test: 0.31591\n",
      "eps: 215/500, train: 1.34455, test: 0.25502\n",
      "eps: 216/500, train: 1.20721, test: 0.29064\n",
      "eps: 217/500, train: 1.33572, test: 0.31515\n",
      "eps: 218/500, train: 1.33197, test: 0.29147\n",
      "eps: 219/500, train: 1.28008, test: 0.32588\n",
      "eps: 220/500, train: 1.34884, test: 0.36065\n",
      "eps: 221/500, train: 1.24282, test: 0.34451\n",
      "eps: 222/500, train: 1.38067, test: 0.31704\n",
      "eps: 223/500, train: 1.32026, test: 0.31959\n",
      "eps: 224/500, train: 1.43193, test: 0.33514\n",
      "eps: 225/500, train: 1.26137, test: 0.36772\n",
      "eps: 226/500, train: 1.08620, test: 0.36170\n",
      "eps: 227/500, train: 1.27788, test: 0.33310\n",
      "eps: 228/500, train: 1.40509, test: 0.28132\n",
      "eps: 229/500, train: 1.34527, test: 0.27751\n",
      "eps: 230/500, train: 1.29075, test: 0.25700\n",
      "eps: 231/500, train: 1.36499, test: 0.28561\n",
      "eps: 232/500, train: 1.18069, test: 0.32232\n",
      "eps: 233/500, train: 1.45221, test: 0.26699\n",
      "eps: 234/500, train: 1.35680, test: 0.25048\n",
      "eps: 235/500, train: 1.46031, test: 0.28569\n",
      "eps: 236/500, train: 1.33250, test: 0.37595\n",
      "eps: 237/500, train: 1.37110, test: 0.38625\n",
      "eps: 238/500, train: 1.19830, test: 0.36910\n",
      "eps: 239/500, train: 1.30793, test: 0.30072\n",
      "eps: 240/500, train: 1.32430, test: 0.32592\n",
      "eps: 241/500, train: 1.32462, test: 0.34036\n",
      "eps: 242/500, train: 1.36031, test: 0.41031\n",
      "eps: 243/500, train: 1.42201, test: 0.42686\n",
      "eps: 244/500, train: 1.40190, test: 0.37638\n",
      "eps: 245/500, train: 1.39473, test: 0.40866\n",
      "eps: 246/500, train: 1.26853, test: 0.42062\n",
      "eps: 247/500, train: 1.34938, test: 0.36609\n",
      "eps: 248/500, train: 1.29152, test: 0.35994\n",
      "eps: 249/500, train: 1.41693, test: 0.39116\n",
      "eps: 250/500, train: 1.35415, test: 0.36590\n",
      "eps: 251/500, train: 1.32877, test: 0.36810\n",
      "eps: 252/500, train: 1.11972, test: 0.35643\n",
      "eps: 253/500, train: 1.34717, test: 0.39399\n",
      "eps: 254/500, train: 1.29790, test: 0.36024\n",
      "eps: 255/500, train: 1.37612, test: 0.32842\n",
      "eps: 256/500, train: 1.33987, test: 0.37124\n",
      "eps: 257/500, train: 1.60635, test: 0.40329\n",
      "eps: 258/500, train: 1.58241, test: 0.41960\n",
      "eps: 259/500, train: 1.44609, test: 0.47104\n",
      "eps: 260/500, train: 1.34314, test: 0.39339\n",
      "eps: 261/500, train: 1.46295, test: 0.43453\n",
      "eps: 262/500, train: 1.39406, test: 0.43347\n",
      "eps: 263/500, train: 1.45102, test: 0.43950\n",
      "eps: 264/500, train: 1.40237, test: 0.47696\n",
      "eps: 265/500, train: 1.57697, test: 0.46484\n",
      "eps: 266/500, train: 1.54700, test: 0.47522\n",
      "eps: 267/500, train: 1.49656, test: 0.44194\n",
      "eps: 268/500, train: 1.43976, test: 0.42699\n",
      "eps: 269/500, train: 1.53034, test: 0.47111\n",
      "eps: 270/500, train: 1.53234, test: 0.46790\n",
      "eps: 271/500, train: 1.58471, test: 0.48753\n",
      "eps: 272/500, train: 1.59321, test: 0.46265\n",
      "eps: 273/500, train: 1.49108, test: 0.48326\n",
      "eps: 274/500, train: 1.63063, test: 0.42693\n",
      "eps: 275/500, train: 1.47647, test: 0.45884\n",
      "eps: 276/500, train: 1.56941, test: 0.46100\n",
      "eps: 277/500, train: 1.47266, test: 0.44830\n",
      "eps: 278/500, train: 1.43739, test: 0.43988\n",
      "eps: 279/500, train: 1.51766, test: 0.44727\n",
      "eps: 280/500, train: 1.48343, test: 0.44945\n",
      "eps: 281/500, train: 1.42748, test: 0.49564\n",
      "eps: 282/500, train: 1.48820, test: 0.47108\n",
      "eps: 283/500, train: 1.48110, test: 0.46672\n",
      "eps: 284/500, train: 1.53637, test: 0.44293\n",
      "eps: 285/500, train: 1.45002, test: 0.44481\n",
      "eps: 286/500, train: 1.58574, test: 0.50334\n",
      "eps: 287/500, train: 1.47600, test: 0.45212\n",
      "eps: 288/500, train: 1.73585, test: 0.52796\n",
      "eps: 289/500, train: 1.52868, test: 0.52796\n",
      "eps: 290/500, train: 1.49867, test: 0.52382\n",
      "eps: 291/500, train: 1.41316, test: 0.39835\n",
      "eps: 292/500, train: 1.42050, test: 0.42027\n",
      "eps: 293/500, train: 1.50312, test: 0.33639\n",
      "eps: 294/500, train: 1.70716, test: 0.41044\n",
      "eps: 295/500, train: 1.54439, test: 0.37961\n",
      "eps: 296/500, train: 1.54824, test: 0.41937\n",
      "eps: 297/500, train: 1.33005, test: 0.38975\n",
      "eps: 298/500, train: 1.48818, test: 0.37064\n",
      "eps: 299/500, train: 1.40153, test: 0.30784\n",
      "eps: 300/500, train: 1.49663, test: 0.35673\n",
      "eps: 301/500, train: 1.43622, test: 0.36221\n",
      "eps: 302/500, train: 1.45229, test: 0.34994\n",
      "eps: 303/500, train: 1.59150, test: 0.33015\n",
      "eps: 304/500, train: 1.42085, test: 0.32560\n",
      "eps: 305/500, train: 1.55816, test: 0.36821\n",
      "eps: 306/500, train: 1.52187, test: 0.41590\n",
      "eps: 307/500, train: 1.55264, test: 0.36134\n",
      "eps: 308/500, train: 1.63698, test: 0.35452\n",
      "eps: 309/500, train: 1.61149, test: 0.37805\n",
      "eps: 310/500, train: 1.51330, test: 0.35150\n",
      "eps: 311/500, train: 1.60388, test: 0.39853\n",
      "eps: 312/500, train: 1.71101, test: 0.30207\n",
      "eps: 313/500, train: 1.45391, test: 0.37120\n",
      "eps: 314/500, train: 1.65915, test: 0.38916\n",
      "eps: 315/500, train: 1.65936, test: 0.43406\n",
      "eps: 316/500, train: 1.46379, test: 0.37912\n",
      "eps: 317/500, train: 1.55717, test: 0.46450\n",
      "eps: 318/500, train: 1.75758, test: 0.39896\n",
      "eps: 319/500, train: 1.63694, test: 0.33780\n",
      "eps: 320/500, train: 1.58721, test: 0.34052\n",
      "eps: 321/500, train: 1.50072, test: 0.30457\n",
      "eps: 322/500, train: 1.54995, test: 0.39028\n",
      "eps: 323/500, train: 1.60154, test: 0.37995\n",
      "eps: 324/500, train: 1.55624, test: 0.44062\n",
      "eps: 325/500, train: 1.64853, test: 0.39351\n",
      "eps: 326/500, train: 1.55547, test: 0.33225\n",
      "eps: 327/500, train: 1.51583, test: 0.31795\n",
      "eps: 328/500, train: 1.62345, test: 0.34231\n",
      "eps: 329/500, train: 1.47637, test: 0.40248\n",
      "eps: 330/500, train: 1.66089, test: 0.48553\n",
      "eps: 331/500, train: 1.75397, test: 0.51992\n",
      "eps: 332/500, train: 1.37697, test: 0.29527\n",
      "eps: 333/500, train: 1.43289, test: 0.39986\n",
      "eps: 334/500, train: 1.32879, test: 0.39248\n",
      "eps: 335/500, train: 1.44731, test: 0.42121\n",
      "eps: 336/500, train: 1.61931, test: 0.46721\n",
      "eps: 337/500, train: 1.50375, test: 0.48147\n",
      "eps: 338/500, train: 1.55736, test: 0.43666\n",
      "eps: 339/500, train: 1.44619, test: 0.42422\n",
      "eps: 340/500, train: 1.36772, test: 0.47134\n",
      "eps: 341/500, train: 1.56364, test: 0.42798\n",
      "eps: 342/500, train: 1.49208, test: 0.38197\n",
      "eps: 343/500, train: 1.59577, test: 0.50533\n",
      "eps: 344/500, train: 1.48653, test: 0.47552\n",
      "eps: 345/500, train: 1.44328, test: 0.50120\n",
      "eps: 346/500, train: 1.62237, test: 0.56311\n",
      "eps: 347/500, train: 1.48668, test: 0.48097\n",
      "eps: 348/500, train: 1.78314, test: 0.50120\n",
      "eps: 349/500, train: 1.66711, test: 0.55346\n",
      "eps: 350/500, train: 1.64646, test: 0.54251\n",
      "eps: 351/500, train: 1.39743, test: 0.50960\n",
      "eps: 352/500, train: 1.55315, test: 0.45516\n",
      "eps: 353/500, train: 1.44722, test: 0.50453\n",
      "eps: 354/500, train: 1.61137, test: 0.44805\n",
      "eps: 355/500, train: 1.40836, test: 0.43732\n",
      "eps: 356/500, train: 1.47124, test: 0.43152\n",
      "eps: 357/500, train: 1.59603, test: 0.43145\n",
      "eps: 358/500, train: 1.45016, test: 0.39887\n",
      "eps: 359/500, train: 1.64494, test: 0.38389\n",
      "eps: 360/500, train: 1.63350, test: 0.37605\n",
      "eps: 361/500, train: 1.72477, test: 0.43942\n",
      "eps: 362/500, train: 1.72915, test: 0.40344\n",
      "eps: 363/500, train: 1.52385, test: 0.40481\n",
      "eps: 364/500, train: 1.53250, test: 0.41531\n",
      "eps: 365/500, train: 1.56388, test: 0.38078\n",
      "eps: 366/500, train: 1.52963, test: 0.35847\n",
      "eps: 367/500, train: 1.57006, test: 0.38985\n",
      "eps: 368/500, train: 1.65150, test: 0.37130\n",
      "eps: 369/500, train: 1.62625, test: 0.38063\n",
      "eps: 370/500, train: 1.34281, test: 0.28781\n",
      "eps: 371/500, train: 1.37898, test: 0.28332\n",
      "eps: 372/500, train: 1.54725, test: 0.37461\n",
      "eps: 373/500, train: 1.65979, test: 0.37042\n",
      "eps: 374/500, train: 1.60265, test: 0.35993\n",
      "eps: 375/500, train: 1.49730, test: 0.33129\n",
      "eps: 376/500, train: 1.57471, test: 0.36049\n",
      "eps: 377/500, train: 1.59298, test: 0.33335\n",
      "eps: 378/500, train: 1.63592, test: 0.36316\n",
      "eps: 379/500, train: 1.42765, test: 0.36135\n",
      "eps: 380/500, train: 1.57063, test: 0.34888\n",
      "eps: 381/500, train: 1.60962, test: 0.32368\n",
      "eps: 382/500, train: 1.63825, test: 0.37623\n",
      "eps: 383/500, train: 1.55785, test: 0.39191\n",
      "eps: 384/500, train: 1.49709, test: 0.34385\n",
      "eps: 385/500, train: 1.59265, test: 0.38919\n",
      "eps: 386/500, train: 1.89475, test: 0.40989\n",
      "eps: 387/500, train: 1.54024, test: 0.39700\n",
      "eps: 388/500, train: 1.69019, test: 0.44338\n",
      "eps: 389/500, train: 1.69370, test: 0.38085\n",
      "eps: 390/500, train: 1.61724, test: 0.41885\n",
      "eps: 391/500, train: 1.76737, test: 0.41214\n",
      "eps: 392/500, train: 1.79808, test: 0.39215\n",
      "eps: 393/500, train: 1.64928, test: 0.39866\n",
      "eps: 394/500, train: 1.60584, test: 0.35449\n",
      "eps: 395/500, train: 1.73494, test: 0.39383\n",
      "eps: 396/500, train: 1.71446, test: 0.35440\n",
      "eps: 397/500, train: 1.53322, test: 0.47959\n",
      "eps: 398/500, train: 1.59391, test: 0.45897\n",
      "eps: 399/500, train: 1.62361, test: 0.46515\n",
      "eps: 400/500, train: 1.75911, test: 0.36622\n",
      "eps: 401/500, train: 1.80344, test: 0.52324\n",
      "eps: 402/500, train: 1.38950, test: 0.37926\n",
      "eps: 403/500, train: 1.58751, test: 0.41326\n",
      "eps: 404/500, train: 1.56516, test: 0.47041\n",
      "eps: 405/500, train: 1.55900, test: 0.35975\n",
      "eps: 406/500, train: 1.66411, test: 0.30733\n",
      "eps: 407/500, train: 1.54882, test: 0.41408\n",
      "eps: 408/500, train: 1.60176, test: 0.40934\n",
      "eps: 409/500, train: 1.66466, test: 0.44252\n",
      "eps: 410/500, train: 1.58027, test: 0.40742\n",
      "eps: 411/500, train: 1.69657, test: 0.37535\n",
      "eps: 412/500, train: 1.67046, test: 0.41183\n",
      "eps: 413/500, train: 1.67062, test: 0.39424\n",
      "eps: 414/500, train: 1.65939, test: 0.29791\n",
      "eps: 415/500, train: 1.76473, test: 0.41123\n",
      "eps: 416/500, train: 1.51247, test: 0.47490\n",
      "eps: 417/500, train: 1.73225, test: 0.43449\n",
      "eps: 418/500, train: 1.76957, test: 0.40115\n",
      "eps: 419/500, train: 1.81814, test: 0.44987\n",
      "eps: 420/500, train: 1.59124, test: 0.42128\n",
      "eps: 421/500, train: 1.68259, test: 0.45782\n",
      "eps: 422/500, train: 1.58357, test: 0.41559\n",
      "eps: 423/500, train: 1.65707, test: 0.37220\n",
      "eps: 424/500, train: 1.52085, test: 0.33067\n",
      "eps: 425/500, train: 1.57160, test: 0.28446\n",
      "eps: 426/500, train: 1.55043, test: 0.39911\n",
      "eps: 427/500, train: 1.55145, test: 0.32753\n",
      "eps: 428/500, train: 1.65539, test: 0.36637\n",
      "eps: 429/500, train: 1.69427, test: 0.37261\n",
      "eps: 430/500, train: 1.50558, test: 0.36088\n",
      "eps: 431/500, train: 1.58147, test: 0.39865\n",
      "eps: 432/500, train: 1.62529, test: 0.41113\n",
      "eps: 433/500, train: 1.67400, test: 0.42321\n",
      "eps: 434/500, train: 1.71686, test: 0.46284\n",
      "eps: 435/500, train: 1.74331, test: 0.45958\n",
      "eps: 436/500, train: 1.78120, test: 0.48587\n",
      "eps: 437/500, train: 1.64723, test: 0.42651\n",
      "eps: 438/500, train: 1.66828, test: 0.44953\n",
      "eps: 439/500, train: 1.57223, test: 0.39110\n",
      "eps: 440/500, train: 1.68421, test: 0.37495\n",
      "eps: 441/500, train: 1.75256, test: 0.37380\n",
      "eps: 442/500, train: 1.69841, test: 0.34557\n",
      "eps: 443/500, train: 1.68600, test: 0.37702\n",
      "eps: 444/500, train: 1.60332, test: 0.32938\n",
      "eps: 445/500, train: 1.82935, test: 0.39094\n",
      "eps: 446/500, train: 1.79428, test: 0.38656\n",
      "eps: 447/500, train: 1.78580, test: 0.39875\n",
      "eps: 448/500, train: 1.93023, test: 0.43851\n",
      "eps: 449/500, train: 1.71242, test: 0.37703\n",
      "eps: 450/500, train: 1.74090, test: 0.37129\n",
      "eps: 451/500, train: 1.98202, test: 0.40594\n",
      "eps: 452/500, train: 1.88173, test: 0.38504\n",
      "eps: 453/500, train: 1.60311, test: 0.39484\n",
      "eps: 454/500, train: 1.77223, test: 0.38658\n",
      "eps: 455/500, train: 1.76651, test: 0.37887\n",
      "eps: 456/500, train: 1.60798, test: 0.41107\n",
      "eps: 457/500, train: 1.61545, test: 0.50060\n",
      "eps: 458/500, train: 1.67107, test: 0.35361\n",
      "eps: 459/500, train: 1.73634, test: 0.36025\n",
      "eps: 460/500, train: 1.68364, test: 0.37103\n",
      "eps: 461/500, train: 1.75842, test: 0.37103\n",
      "eps: 462/500, train: 1.86650, test: 0.36775\n",
      "eps: 463/500, train: 1.73393, test: 0.34028\n",
      "eps: 464/500, train: 1.72701, test: 0.34083\n",
      "eps: 465/500, train: 1.77404, test: 0.30727\n",
      "eps: 466/500, train: 1.76073, test: 0.29462\n",
      "eps: 467/500, train: 1.84881, test: 0.28477\n",
      "eps: 468/500, train: 1.75463, test: 0.24603\n",
      "eps: 469/500, train: 1.70801, test: 0.34448\n",
      "eps: 470/500, train: 1.55218, test: 0.19069\n",
      "eps: 471/500, train: 1.60820, test: 0.27894\n",
      "eps: 472/500, train: 1.90177, test: 0.27173\n",
      "eps: 473/500, train: 1.84255, test: 0.28986\n",
      "eps: 474/500, train: 1.71846, test: 0.34975\n",
      "eps: 475/500, train: 1.75763, test: 0.42134\n",
      "eps: 476/500, train: 1.65335, test: 0.36418\n",
      "eps: 477/500, train: 1.83885, test: 0.39145\n",
      "eps: 478/500, train: 1.75170, test: 0.43778\n",
      "eps: 479/500, train: 1.78814, test: 0.44989\n",
      "eps: 480/500, train: 1.65388, test: 0.39820\n",
      "eps: 481/500, train: 1.86275, test: 0.41592\n",
      "eps: 482/500, train: 1.71414, test: 0.34934\n",
      "eps: 483/500, train: 1.76091, test: 0.34474\n",
      "eps: 484/500, train: 1.89161, test: 0.34839\n",
      "eps: 485/500, train: 1.85540, test: 0.36391\n",
      "eps: 486/500, train: 1.77117, test: 0.30945\n",
      "eps: 487/500, train: 1.69020, test: 0.30995\n",
      "eps: 488/500, train: 1.76502, test: 0.32558\n",
      "eps: 489/500, train: 1.77585, test: 0.34682\n",
      "eps: 490/500, train: 1.79972, test: 0.32042\n",
      "eps: 491/500, train: 1.75072, test: 0.33211\n",
      "eps: 492/500, train: 1.82102, test: 0.29600\n",
      "eps: 493/500, train: 1.90855, test: 0.36776\n",
      "eps: 494/500, train: 1.82811, test: 0.29343\n",
      "eps: 495/500, train: 1.87539, test: 0.32669\n",
      "eps: 496/500, train: 1.71959, test: 0.31619\n",
      "eps: 497/500, train: 1.79914, test: 0.39278\n",
      "eps: 498/500, train: 1.74863, test: 0.35966\n",
      "eps: 499/500, train: 1.76202, test: 0.40398\n",
      "eps: 500/500, train: 1.89642, test: 0.37728\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6dERWoL9sKn0",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "outputId": "2bfc7e40-2602-431d-d417-c6cb881c24bb"
   },
   "source": [
    "plt.plot(train_rewards)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7febd3388650>]"
      ]
     },
     "metadata": {},
     "execution_count": 51
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "vQiAl-PGWsKv",
    "outputId": "d651737a-e7c1-4d9a-e193-6c8211401a2a"
   },
   "source": [
    "plt.plot(test_rewards)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7febd332f750>]"
      ]
     },
     "metadata": {},
     "execution_count": 52
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ]
  }
 ]
}
